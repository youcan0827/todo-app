#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import csv
import datetime
from typing import Optional

try:
    from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings
    from llama_index.core.node_parser import SentenceSplitter
    import pdfplumber
    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False

RAG_CSV_FILE = "rag_conversations.csv"
RAG_CSV_HEADERS = ["timestamp", "pdf_file", "question", "answer"]

def initialize_rag_csv() -> None:
    if not os.path.exists(RAG_CSV_FILE):
        with open(RAG_CSV_FILE, 'w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow(RAG_CSV_HEADERS)

def save_rag_conversation(pdf_file: str, question: str, answer: str) -> None:
    with open(RAG_CSV_FILE, 'a', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        writer.writerow([timestamp, pdf_file, question, answer])

def extract_pdf_text(pdf_path: str) -> str:
    text = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
    return text

def rag_mode() -> None:
    if not RAG_AVAILABLE:
        print("\nâŒ RAGãƒ¢ãƒ¼ãƒ‰ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“")
        print("å¿…è¦ãªä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š")
        print("pip install llama-index pdfplumber")
        return
    
    initialize_rag_csv()
    
    print("\n=== RAGãƒ¢ãƒ¼ãƒ‰ ===")
    print("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è³ªå•ã—ã¦ãã ã•ã„")
    
    pdf_path = input("PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
    
    if not os.path.exists(pdf_path):
        print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    if not pdf_path.lower().endswith('.pdf'):
        print("âŒ PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        return
    
    try:
        print("ğŸ“„ PDFã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
        pdf_text = extract_pdf_text(pdf_path)
        
        if not pdf_text.strip():
            print("âŒ PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        print("ğŸ§  ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
        
        with open("temp_text.txt", "w", encoding="utf-8") as temp_file:
            temp_file.write(pdf_text)
        
        documents = SimpleDirectoryReader(input_files=["temp_text.txt"]).load_data()
        
        Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=50)
        index = VectorStoreIndex.from_documents(documents)
        query_engine = index.as_query_engine()
        
        os.remove("temp_text.txt")
        
        print("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†ï¼")
        print("\nPDFã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„ï¼ˆ'exit'ã§çµ‚äº†ï¼‰")
        
        pdf_filename = os.path.basename(pdf_path)
        
        while True:
            question = input("\nè³ªå•: ").strip()
            
            if question.lower() == 'exit':
                break
            
            if not question:
                print("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                continue
            
            print("ğŸ¤– å›ç­”ã‚’ç”Ÿæˆä¸­...")
            response = query_engine.query(question)
            answer = str(response)
            
            print(f"\nå›ç­”: {answer}")
            
            save_rag_conversation(pdf_filename, question, answer)
            print("âœ… ä¼šè©±ã‚’è¨˜éŒ²ã—ã¾ã—ãŸ")
        
        print("\nRAGãƒ¢ãƒ¼ãƒ‰ã‚’çµ‚äº†ã—ã¾ã™")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        if os.path.exists("temp_text.txt"):
            os.remove("temp_text.txt")