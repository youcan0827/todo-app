#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import csv
import datetime
from typing import Optional

try:
    from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Settings
    from llama_index.core.node_parser import SentenceSplitter
    from llama_index.core.prompts import PromptTemplate
    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False

RAG_CSV_FILE = "rag_conversations.csv"
RAG_CSV_HEADERS = ["timestamp", "pdf_file", "question", "answer"]

def initialize_rag_csv() -> None:
    if not os.path.exists(RAG_CSV_FILE):
        with open(RAG_CSV_FILE, 'w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow(RAG_CSV_HEADERS)

def save_rag_conversation(pdf_file: str, question: str, answer: str) -> None:
    with open(RAG_CSV_FILE, 'a', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        writer.writerow([timestamp, pdf_file, question, answer])


def rag_mode() -> None:
    if not RAG_AVAILABLE:
        print("\nâŒ RAGãƒ¢ãƒ¼ãƒ‰ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“")
        print("å¿…è¦ãªä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š")
        print("pip install llama-index")
        return
    
    initialize_rag_csv()
    
    print("\n=== RAGãƒ¢ãƒ¼ãƒ‰ ===")
    print("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è³ªå•ã—ã¦ãã ã•ã„")
    
    pdf_path = input("PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
    
    if not os.path.exists(pdf_path):
        print("âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    if not pdf_path.lower().endswith('.pdf'):
        print("âŒ PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
        return
    
    try:
        print("ğŸ“„ PDFã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
        documents = SimpleDirectoryReader(input_files=[pdf_path]).load_data()

        if not documents:
            print("âŒ PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return

        print("ğŸ§  ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
        Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=50)
        index = VectorStoreIndex.from_documents(documents)

        qa_prompt_tmpl = PromptTemplate(
            "ã‚ãªãŸã¯æ—¥æœ¬èªã§å›ç­”ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            "ä»¥ä¸‹ã®æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ã€è³ªå•ã«æ—¥æœ¬èªã§æ­£ç¢ºã«ç­”ãˆã¦ãã ã•ã„ã€‚\n\n"
            "æƒ…å ±:\n{context_str}\n\n"
            "è³ªå•: {query_str}\n"
            "å›ç­”:"
        )
        query_engine = index.as_query_engine(text_qa_template=qa_prompt_tmpl)
        
        print("âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†ï¼")
        print("\nPDFã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„ï¼ˆ'exit'ã§çµ‚äº†ï¼‰")
        
        pdf_filename = os.path.basename(pdf_path)
        
        while True:
            question = input("\nè³ªå•: ").strip()
            
            if question.lower() == 'exit':
                break
            
            if not question:
                print("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                continue
            
            print("ğŸ¤– å›ç­”ã‚’ç”Ÿæˆä¸­...")
            response = query_engine.query(question)
            answer = str(response)
            
            print(f"\nå›ç­”: {answer}")
            
            save_rag_conversation(pdf_filename, question, answer)
            print("âœ… ä¼šè©±ã‚’è¨˜éŒ²ã—ã¾ã—ãŸ")
        
        print("\nRAGãƒ¢ãƒ¼ãƒ‰ã‚’çµ‚äº†ã—ã¾ã™")

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")