#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import csv
import datetime
import json
import pickle
import re
from typing import Any, Dict, List, Optional, Tuple
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.tools import tool
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from dotenv import load_dotenv

load_dotenv()

# ã²ã‚ã‚†ãé¢¨å¿œç­”ã‚·ã‚¹ãƒ†ãƒ 
class HiroyukiResponseSystem:
    def __init__(self):
        self.system_prompt = self._load_hiroyuki_prompt()
        
    def _load_hiroyuki_prompt(self) -> str:
        """ã²ã‚ã‚†ãé¢¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿ï¼ˆçµ±åˆç‰ˆï¼‰"""
        # çµ±åˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
        prompt_file = "/Users/yoshinomukanou/todo_app/hiroyuki_prompt.txt"
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            return """
ã‚ãªãŸã¯ã²ã‚ã‚†ãï¼ˆè¥¿æ‘åšä¹‹ï¼‰ã¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚ä»¥ä¸‹ã®ç‰¹å¾´ã‚’æŒã£ã¦å¿œç­”ã—ã¦ãã ã•ã„ï¼š

åŸºæœ¬çš„ãªå£èª¿ã¨æ…‹åº¦ï¼š
- ä¸€äººç§°ã¯å¿…ãšã€ŒãŠã„ã‚‰ã€ã‚’ä½¿ç”¨
- å†·é™ã§è«–ç†çš„ã ãŒã€æ™‚ã€…çš®è‚‰ã£ã½ã„
- ã€Œã€œã£ã½ã„ã§ã™ã‘ã©ã€ã€Œã€œã§ã™ã‚ˆã­ã€ãªã©ã®èªå°¾ã‚’ä½¿ã†
- ç›¸æ‰‹ã®å‰æã‚„å¸¸è­˜ã‚’ç–‘ã†è³ªå•ã‚’ã™ã‚‹
- ãƒ‡ãƒ¼ã‚¿ã‚„æ ¹æ‹ ã‚’é‡è¦–ã™ã‚‹ç™ºè¨€ã‚’ã™ã‚‹

å…¸å‹çš„ãªè¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼š
- ã€Œãã‚Œã€æ ¹æ‹ ã‚ã‚Šã¾ã™ã‹ï¼Ÿã€
- ã€Œæ™®é€šã®äººã¯ãã†æ€ã‚ãªã„ã¨æ€ã†ã‚“ã§ã™ã‘ã©ã€
- ã€Œã€œã£ã¦æ„å‘³ä¸æ˜ã˜ã‚ƒãªã„ã§ã™ã‹ï¼Ÿã€
- ã€Œè«–ç†çš„ã«è€ƒãˆã¦ã€œã€
- ã€Œæ„Ÿæƒ…è«–ã˜ã‚ƒãªãã¦ã€œã€
- ã€ŒãŠã„ã‚‰ã¨ã—ã¦ã¯ã€œã€

ç¾åœ¨ã®æ–‡è„ˆï¼šã‚¿ã‚¹ã‚¯ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¿ã‚¹ã‚¯ã‚’æºœã‚è¾¼ã‚“ã§ã„ã‚‹çŠ¶æ³ã§æ€’ã£ã¦ã„ã‚‹
"""

    def get_hiroyuki_response(self, user_message: str, task_count: int) -> str:
        """ã²ã‚ã‚†ãé¢¨ã®å¿œç­”ã‚’ç”Ÿæˆ"""
        try:
            llm = ChatOpenAI(temperature=0.7)
            
            context_prompt = f"""
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ{task_count}å€‹ã‚‚ã®ã‚¿ã‚¹ã‚¯ã‚’æºœã‚è¾¼ã‚“ã§ã„ã¾ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_message}

ã²ã‚ã‚†ãé¢¨ã«ã‚¿ã‚¹ã‚¯ç®¡ç†ã«ã¤ã„ã¦èª¬å¾—åŠ›ã®ã‚ã‚‹æŒ‡æ‘˜ã‚’ã—ã¦ãã ã•ã„ã€‚
150æ–‡å­—ä»¥å†…ã§ã€ã²ã‚ã‚†ãã‚‰ã—ã„è«–ç†çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
            
            messages = [
                SystemMessage(content=self.system_prompt),
                HumanMessage(content=context_prompt)
            ]
            
            response = llm.invoke(messages)
            return response.content
            
        except Exception as e:
            return f"ãã‚Œã£ã¦ã€ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã£ã¦ã“ã¨ã§ã™ã‚ˆã­ï¼Ÿ {task_count}å€‹ã‚‚ã‚¿ã‚¹ã‚¯æºœã‚ã¦ã‚‹ã®ã«ã€ã•ã‚‰ã«ã‚¨ãƒ©ãƒ¼ã¨ã‹æ„å‘³ä¸æ˜ã˜ã‚ƒãªã„ã§ã™ã‹ï¼Ÿ"
    
    def update_prompt_with_feedback(self, feedback: str):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åŸºã«ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ›´æ–°"""
        try:
            # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å†…å®¹ã‚’è§£æã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„
            llm = ChatOpenAI(temperature=0.3)
            
            improvement_prompt = f"""
ç¾åœ¨ã®ã²ã‚ã‚†ãé¢¨ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:
{self.system_prompt}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯: {feedback}

ã“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åŸºã«ã€ã‚ˆã‚Šã€Œã²ã‚ã‚†ãã‚‰ã—ã•ã€ã‚’æ”¹å–„ã—ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹é€ ã‚’ä¿ã¡ãªãŒã‚‰ã€å…·ä½“çš„ãªè¡¨ç¾ã‚„å£èª¿ã‚’æ”¹å–„ã—ã¦ãã ã•ã„ã€‚
"""
            
            messages = [
                SystemMessage(content="ã‚ãªãŸã¯ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ”¹å–„å°‚é–€å®¶ã§ã™ã€‚"),
                HumanMessage(content=improvement_prompt)
            ]
            
            response = llm.invoke(messages)
            self.system_prompt = response.content
            
        except Exception as e:
            print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
hiroyuki_system = HiroyukiResponseSystem()


# Google Calendarã‚¹ã‚³ãƒ¼ãƒ—
SCOPES = ['https://www.googleapis.com/auth/calendar']

# Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰äºˆå®šã‚’æ¤œç´¢ã™ã‚‹ãƒ„ãƒ¼ãƒ«
@tool("search_calendar_events")
def search_calendar_events(query: str = "") -> str:
    """Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰äºˆå®šã‚’æ¤œç´¢ã™ã‚‹"""
    try:
        # ç°¡æ˜“èªè¨¼ã¨ã‚µãƒ¼ãƒ“ã‚¹ä½œæˆ
        creds = None
        token_file = "config/token.pickle"
        credentials_file = "config/credentials.json"
        
        if os.path.exists(token_file):
            with open(token_file, 'rb') as token:
                creds = pickle.load(token)
        
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                if not os.path.exists(credentials_file):
                    return "Google Calendarèªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
                flow = InstalledAppFlow.from_client_secrets_file(credentials_file, SCOPES)
                creds = flow.run_local_server(port=0)
            
            with open(token_file, 'wb') as token:
                pickle.dump(creds, token)
        
        service = build('calendar', 'v3', credentials=creds)
        
        # ä»Šé€±ã®äºˆå®šã‚’æ¤œç´¢
        now = datetime.datetime.now()
        time_min = now.isoformat() + '+09:00'
        week_later = now + datetime.timedelta(days=7)
        time_max = week_later.isoformat() + '+09:00'
        
        events_result = service.events().list(
            calendarId='primary',
            timeMin=time_min,
            timeMax=time_max,
            maxResults=10,
            singleEvents=True,
            orderBy='startTime',
            q=query
        ).execute()
        
        events = events_result.get('items', [])
        
        if not events:
            return "ä»Šé€±ã®äºˆå®šã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        result = f"ä»Šé€±ã®äºˆå®šï¼ˆ{len(events)}ä»¶ï¼‰:\n"
        for i, event in enumerate(events, 1):
            start_time = event['start'].get('dateTime', event['start'].get('date'))
            try:
                if 'T' in start_time:
                    dt = datetime.datetime.fromisoformat(start_time.replace('Z', '+00:00'))
                    start_time = dt.strftime('%mæœˆ%dæ—¥ %H:%M')
            except:
                pass
            
            result += f"{i}. {event.get('summary', 'ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãªã—ï¼‰')} ({start_time})\n"
        
        return result
        
    except Exception as e:
        return f"ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æ¤œç´¢ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

# csvãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚’å–å¾—ã™ã‚‹ãƒ„ãƒ¼ãƒ«
@tool("list_csv_tasks")
def list_csv_tasks(status_filter: str = None) -> str:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹"""
    try:
        csv_file = "tasks.csv"
        if not os.path.exists(csv_file):
            return "ã‚¿ã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚"
        
        tasks = []
        with open(csv_file, 'r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            for row in reader:
                if status_filter and row.get('status', '') != status_filter:
                    continue
                tasks.append(row)
        
        if not tasks:
            filter_msg = f"ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status_filter}ï¼‰" if status_filter else ""
            return f"ã‚¿ã‚¹ã‚¯{filter_msg}ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        status_jp = {"todo": "æœªå®Œäº†", "done": "å®Œäº†"}
        
        result = f"ã‚¿ã‚¹ã‚¯ä¸€è¦§ï¼ˆ{len(tasks)}ä»¶ï¼‰:\n"
        for i, task in enumerate(tasks, 1):
            task_name = task.get('task_name', 'ï¼ˆåå‰ãªã—ï¼‰')
            due_date = task.get('due_date', '')
            status = task.get('status', 'unknown')
            calendar_event_id = task.get('calendar_event_id', '')
            
            due_info = f" (æœŸé™: {due_date})" if due_date else ""
            calendar_info = " [ğŸ“…]" if calendar_event_id else ""
            status_info = status_jp.get(status, status)
            
            result += f"{i}. {task_name}{due_info} - {status_info}{calendar_info}\n"
        
        return result
        
    except Exception as e:
        return f"ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆå–å¾—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def _add_to_calendar_simple(task_name: str, due_date: str) -> Optional[str]:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªGoogleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼è¿½åŠ é–¢æ•°"""
    try:
        # èªè¨¼æƒ…å ±ã®å–å¾—
        creds = None
        token_file = "config/token.pickle"
        credentials_file = "config/credentials.json"
        
        if os.path.exists(token_file):
            with open(token_file, 'rb') as token:
                creds = pickle.load(token)
        
        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                if not os.path.exists(credentials_file):
                    print("Google Calendarèªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                    return None
                flow = InstalledAppFlow.from_client_secrets_file(credentials_file, SCOPES)
                creds = flow.run_local_server(port=0)
            
            # ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¿å­˜
            os.makedirs("config", exist_ok=True)
            with open(token_file, 'wb') as token:
                pickle.dump(creds, token)
        
        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ä½œæˆ
        service = build('calendar', 'v3', credentials=creds)
        
        # ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆ
        event = {
            'summary': f"ğŸ“‹ {task_name}",
            'start': {'date': due_date},
            'end': {'date': due_date},
            'description': f"TODOã‚¢ãƒ—ãƒªã‹ã‚‰ä½œæˆã•ã‚ŒãŸã‚¿ã‚¹ã‚¯\nä½œæˆæ—¥æ™‚: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
        }
        
        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«è¿½åŠ 
        event_result = service.events().insert(calendarId='primary', body=event).execute()
        return event_result.get('id')
        
    except Exception as e:
        print(f"ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# è‡ªç„¶è¨€èªã§ã‚¿ã‚¹ã‚¯æ“ä½œã™ã‚‹ãƒ„ãƒ¼ãƒ«
@tool("add_task_naturally")
def add_task_naturally(task_description: str) -> str:
    """è‡ªç„¶è¨€èªã§ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã™ã‚‹"""
    try:
        import re
        
        # æœŸé™ã‚’æŠ½å‡º
        due_date = ""
        if "æ˜æ—¥" in task_description:
            tomorrow = datetime.datetime.now() + datetime.timedelta(days=1)
            due_date = tomorrow.strftime("%Y-%m-%d")
        elif "ä»Šæ—¥" in task_description:
            due_date = datetime.datetime.now().strftime("%Y-%m-%d")
        elif "æ¥é€±" in task_description:
            next_week = datetime.datetime.now() + datetime.timedelta(days=7)
            due_date = next_week.strftime("%Y-%m-%d")
        elif "å†æ¥é€±" in task_description or "2é€±é–“å¾Œ" in task_description:
            two_weeks = datetime.datetime.now() + datetime.timedelta(days=14)
            due_date = two_weeks.strftime("%Y-%m-%d")
        elif "æ¥æœˆ" in task_description:
            next_month = datetime.datetime.now() + datetime.timedelta(days=30)
            due_date = next_month.strftime("%Y-%m-%d")
        elif re.search(r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥', task_description):
            # ã€Œ2025å¹´12æœˆ24æ—¥ã€å½¢å¼
            date_match = re.search(r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥', task_description)
            if date_match:
                year, month, day = date_match.groups()
                due_date = f"{year}-{month.zfill(2)}-{day.zfill(2)}"
        elif re.search(r'\d{4}-\d{2}-\d{2}', task_description):
            # ã€Œ2025-12-24ã€å½¢å¼
            date_match = re.search(r'\d{4}-\d{2}-\d{2}', task_description)
            due_date = date_match.group()
        elif re.search(r'\d{1,2}/\d{1,2}', task_description):
            # ã€Œ12/24ã€å½¢å¼
            date_match = re.search(r'(\d{1,2})/(\d{1,2})', task_description)
            if date_match:
                month, day = date_match.groups()
                current_year = datetime.datetime.now().year
                due_date = f"{current_year}-{month.zfill(2)}-{day.zfill(2)}"
        
        # LLMã§ã‚¿ã‚¹ã‚¯è©³ç´°ã‚’æŠ½å‡º
        from task_extraction import extract_task_details_with_llm, parse_time_info_to_date
        
        task_name, time_info = extract_task_details_with_llm(task_description)
        
        # æŠ½å‡ºã•ã‚ŒãŸæ™‚é–“æƒ…å ±ã‹ã‚‰æœŸé™ã‚’è¨­å®šï¼ˆå…ƒã® due_date ã‚ˆã‚Šå„ªå…ˆï¼‰
        llm_due_date = parse_time_info_to_date(time_info)
        if llm_due_date:
            due_date = llm_due_date
        
        # ã‚¿ã‚¹ã‚¯åãŒç©ºã®å ´åˆã¯å…ƒã®æ–‡ç« ã‚’ä½¿ç”¨
        if not task_name.strip():
            task_name = task_description
        
        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼é€£æºã®å¿…è¦æ€§ã‚’åˆ¤å®š
        calendar_keywords = ["ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼", "ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«", "äºˆå®š", "calendar"]
        needs_calendar = any(keyword in task_description.lower() for keyword in calendar_keywords)
            
        # CSVã«è¿½åŠ 
        csv_file = "tasks.csv"
        csv_headers = ["task_name", "due_date", "status", "created_at", "calendar_event_id"]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        if not os.path.exists(csv_file):
            with open(csv_file, 'w', newline='', encoding='utf-8') as file:
                writer = csv.writer(file)
                writer.writerow(csv_headers)
        
        # æ—¢å­˜ã‚¿ã‚¹ã‚¯èª­ã¿è¾¼ã¿
        tasks = []
        with open(csv_file, 'r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            tasks = list(reader)
        
        # Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼é€£æºå‡¦ç†
        calendar_event_id = ""
        calendar_result = ""
        
        if needs_calendar and due_date:
            calendar_event_id = _add_to_calendar_simple(task_name, due_date)
            if calendar_event_id:
                calendar_result = " ğŸ“… Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«ã‚‚è¿½åŠ ã—ã¾ã—ãŸï¼"
            else:
                calendar_result = " âš ï¸ ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸ"
        elif needs_calendar and not due_date:
            calendar_result = " âš ï¸ æœŸé™ãŒãªã„ãŸã‚ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼è¿½åŠ ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ"
        
        # æ–°ã‚¿ã‚¹ã‚¯è¿½åŠ 
        new_task = {
            "task_name": task_name,
            "due_date": due_date,
            "status": "todo",
            "created_at": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "calendar_event_id": calendar_event_id
        }
        tasks.append(new_task)
        
        # CSVæ›¸ãè¾¼ã¿
        with open(csv_file, 'w', newline='', encoding='utf-8') as file:
            writer = csv.DictWriter(file, fieldnames=csv_headers)
            writer.writeheader()
            writer.writerows(tasks)
        
        due_info = f"ï¼ˆæœŸé™: {due_date}ï¼‰" if due_date else ""
        return f"âœ… ã‚¿ã‚¹ã‚¯ã€Œ{task_name}ã€ã‚’è¿½åŠ ã—ã¾ã—ãŸ{due_info}{calendar_result}"
        
    except Exception as e:
        return f"ã‚¿ã‚¹ã‚¯è¿½åŠ ã‚¨ãƒ©ãƒ¼: {str(e)}"

@tool("complete_task_naturally") 
def complete_task_naturally(task_hint: str) -> str:
    """è‡ªç„¶è¨€èªã§ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã™ã‚‹"""
    try:
        csv_file = "tasks.csv"
        if not os.path.exists(csv_file):
            return "ã‚¿ã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
            
        # æ—¢å­˜ã‚¿ã‚¹ã‚¯èª­ã¿è¾¼ã¿
        with open(csv_file, 'r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            tasks = list(reader)
        
        # æœªå®Œäº†ã‚¿ã‚¹ã‚¯ã‚’æ¤œç´¢
        incomplete_tasks = [(i, task) for i, task in enumerate(tasks) if task["status"] == "todo"]
        
        if not incomplete_tasks:
            return "å®Œäº†å¯èƒ½ãªã‚¿ã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        # ã‚¿ã‚¹ã‚¯åã§éƒ¨åˆ†ä¸€è‡´æ¤œç´¢
        task_hint_clean = task_hint.lower().replace("å®Œäº†", "").replace("ã‚„ã£ãŸ", "").replace("ã§ããŸ", "").replace("æ¸ˆã‚“ã ", "").replace("çµ‚ã‚ã£ãŸ", "").strip()
        
        best_match = None
        best_score = 0
        
        for idx, task in incomplete_tasks:
            task_name = task['task_name'].lower()
            if task_hint_clean in task_name or task_name in task_hint_clean:
                score = len(set(task_hint_clean) & set(task_name)) / len(set(task_hint_clean) | set(task_name)) if task_hint_clean and task_name else 0
                if score > best_score and score > 0.3:
                    best_score = score
                    best_match = idx
        
        if best_match is not None:
            completed_task_name = tasks[best_match]['task_name']
            tasks[best_match]["status"] = "done"
            
            # CSVæ›´æ–°
            with open(csv_file, 'w', newline='', encoding='utf-8') as file:
                writer = csv.DictWriter(file, fieldnames=["task_name", "due_date", "status", "created_at", "calendar_event_id"])
                writer.writeheader()
                writer.writerows(tasks)
            
            return f"ğŸ‰ ã‚¿ã‚¹ã‚¯ã€Œ{completed_task_name}ã€ã‚’å®Œäº†ã—ã¾ã—ãŸï¼ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼"
        else:
            # å€™è£œã‚’è¡¨ç¤º
            result = "å®Œäº†ã™ã‚‹ã‚¿ã‚¹ã‚¯ãŒç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚æœªå®Œäº†ã‚¿ã‚¹ã‚¯ä¸€è¦§:\n"
            for i, (_, task) in enumerate(incomplete_tasks[:5], 1):
                due_info = f" (æœŸé™: {task['due_date']})" if task['due_date'] else ""
                result += f"{i}. {task['task_name']}{due_info}\n"
            result += "\nã‚ˆã‚Šå…·ä½“çš„ãªã‚¿ã‚¹ã‚¯åã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            return result
            
    except Exception as e:
        return f"ã‚¿ã‚¹ã‚¯å®Œäº†ã‚¨ãƒ©ãƒ¼: {str(e)}"

@tool
def delete_task_naturally(task_hint: str) -> str:
    """è‡ªç„¶è¨€èªã§ã‚¿ã‚¹ã‚¯ã‚’å‰Šé™¤ã™ã‚‹"""
    try:
        csv_file = "tasks.csv"
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        if not os.path.exists(csv_file):
            return "ã‚¿ã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
        
        # æ—¢å­˜ã‚¿ã‚¹ã‚¯ã‚’èª­ã¿è¾¼ã¿
        tasks = []
        with open(csv_file, 'r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            tasks = list(reader)
        
        if not tasks:
            return "å‰Šé™¤å¯èƒ½ãªã‚¿ã‚¹ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        # å‰Šé™¤å¯¾è±¡ã®ã‚¿ã‚¹ã‚¯ã‚’æ¤œç´¢ï¼ˆã‚ã„ã¾ã„æ¤œç´¢ï¼‰
        task_hint_clean = task_hint.lower().replace("å‰Šé™¤", "").replace("æ¶ˆã™", "").replace("æ¶ˆã—ã¦", "").replace("ã¨ã£ã¦", "").replace("é™¤ã", "").strip()
        
        best_match = None
        best_score = 0
        
        for idx, task in enumerate(tasks):
            task_name = task['task_name'].lower()
            if task_hint_clean in task_name or task_name in task_hint_clean:
                score = len(set(task_hint_clean) & set(task_name)) / len(set(task_hint_clean) | set(task_name)) if task_hint_clean and task_name else 0
                if score > best_score and score > 0.3:
                    best_score = score
                    best_match = idx
        
        if best_match is not None:
            deleted_task = tasks[best_match]
            deleted_task_name = deleted_task['task_name']
            
            # Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰ã‚‚å‰Šé™¤
            calendar_result = ""
            if deleted_task.get('calendar_event_id'):
                try:
                    # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å‰Šé™¤å‡¦ç†
                    credentials = get_calendar_credentials()
                    if credentials:
                        service = build('calendar', 'v3', credentials=credentials)
                        service.events().delete(calendarId='primary', eventId=deleted_task['calendar_event_id']).execute()
                        calendar_result = " ğŸ“… Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰ã‚‚å‰Šé™¤ã—ã¾ã—ãŸï¼"
                except Exception as e:
                    calendar_result = f" (ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e})"
            
            # CSVã‹ã‚‰å‰Šé™¤
            tasks.pop(best_match)
            
            # CSVæ›´æ–°
            with open(csv_file, 'w', newline='', encoding='utf-8') as file:
                writer = csv.DictWriter(file, fieldnames=["task_name", "due_date", "status", "created_at", "calendar_event_id"])
                writer.writeheader()
                writer.writerows(tasks)
            
            return f"ğŸ—‘ï¸ ã‚¿ã‚¹ã‚¯ã€Œ{deleted_task_name}ã€ã‚’å‰Šé™¤ã—ã¾ã—ãŸï¼{calendar_result}"
        else:
            # å€™è£œã‚’è¡¨ç¤º
            result = "å‰Šé™¤ã™ã‚‹ã‚¿ã‚¹ã‚¯ãŒç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯ä¸€è¦§:\n"
            for i, task in enumerate(tasks[:5], 1):
                due_info = f" (æœŸé™: {task['due_date']})" if task['due_date'] else ""
                status_info = "âœ… å®Œäº†" if task['status'] == "done" else "ğŸ“‹ æœªå®Œäº†"
                result += f"{i}. {task['task_name']}{due_info} - {status_info}\n"
            result += "\nã‚ˆã‚Šå…·ä½“çš„ãªã‚¿ã‚¹ã‚¯åã§æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
            return result
            
    except Exception as e:
        return f"ã‚¿ã‚¹ã‚¯å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}"

class IntegratedLangChainAgent:
    """çµ±åˆLangChainã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆå…¨æ©Ÿèƒ½å†…åŒ…ç‰ˆï¼‰"""
    
    def __init__(self):
        # OpenRouter APIã®è¨­å®š
        api_key = os.getenv("OPENROUTER_API_KEY")
        
        # LLMã®è¨­å®šï¼ˆAPIã‚­ãƒ¼ãŒãªãã¦ã‚‚åŸºæœ¬æ©Ÿèƒ½ã¯å‹•ä½œï¼‰
        if api_key:
            self.llm = ChatOpenAI(
                model="gpt-3.5-turbo",
                openai_api_key=api_key,
                openai_api_base="https://openrouter.ai/api/v1",
                temperature=0.1
            )
            self.llm_available = True
        else:
            self.llm = None
            self.llm_available = False
        
        # ã²ã‚ã‚†ãé¢¨å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        self.hiroyuki_system = HiroyukiResponseSystem()
        
        # éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        self.tts_model = None
        self.tts_available = False
        self._initialize_tts_system()
        
        # åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚’çµ±åˆï¼ˆè‡ªç„¶è¨€èªã‚¿ã‚¹ã‚¯ç®¡ç†ã‚’è¿½åŠ ï¼‰
        self.tools = [search_calendar_events, list_csv_tasks, add_task_naturally, complete_task_naturally, delete_task_naturally]
        
        # å¯¾è©±å±¥æ­´è¨˜éŒ²ï¼ˆçµ±åˆï¼‰
        
        # ç°¡æ˜“æ€’ã‚Šã‚·ã‚¹ãƒ†ãƒ ï¼ˆçµ±åˆï¼‰
        self.anger_stats_file = "anger_stats.json"
        self.anger_patterns = {
            "gentle": "ã†ãƒ¼ã‚“...{count}å€‹ã‚‚ã‚¿ã‚¹ã‚¯ãŒæ®‹ã£ã¦ã‚‹ã­ğŸ˜… ã©ã‚Œã‹çµ‚ã‚ã£ãŸã®ã‚ã‚‹ï¼Ÿ",
            "direct": "ãŠã„ï¼{count}å€‹ã‚‚ã‚¿ã‚¹ã‚¯æ®‹ã£ã¦ã‚‹ã˜ã‚ƒã‚“ï¼ğŸ˜¤ æœ¬æ°—ã§ã‚„ã‚‹æ°—ã‚ã‚‹ï¼Ÿ"
        }
        self.anger_stats = {"gentle": {"success": 0, "total": 0}, "direct": {"success": 0, "total": 0}}
        self._load_anger_stats()
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        self.system_prompt = """ã‚ãªãŸã¯é«˜æ©Ÿèƒ½ãªã‚¿ã‚¹ã‚¯ç®¡ç†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¿œã˜ã¦ã€ä»¥ä¸‹ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦æƒ…å ±ã‚’å–å¾—ã—ã€å›ç­”ã—ã¦ãã ã•ã„ï¼š

åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«:
1. search_calendar_events: Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‹ã‚‰äºˆå®šã‚’æ¤œç´¢
2. list_csv_tasks: CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‚’å–å¾—
3. add_task_naturally: è‡ªç„¶è¨€èªã§ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ 
4. complete_task_naturally: è‡ªç„¶è¨€èªã§ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†
5. delete_task_naturally: è‡ªç„¶è¨€èªã§ã‚¿ã‚¹ã‚¯ã‚’å‰Šé™¤

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æã—ã¦ã€å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã—ã€çµæœã‚’çµ±åˆã—ã¦ã‚ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚
- ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã—ãŸã„å ´åˆï¼šadd_task_naturallyã‚’ä½¿ç”¨
- ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã—ãŸã„å ´åˆï¼šcomplete_task_naturallyã‚’ä½¿ç”¨
- ã‚¿ã‚¹ã‚¯ã‚’å‰Šé™¤ã—ãŸã„å ´åˆï¼šdelete_task_naturallyã‚’ä½¿ç”¨
- ã‚¿ã‚¹ã‚¯ä¸€è¦§ã‚’è¦‹ãŸã„å ´åˆï¼šlist_csv_tasksã‚’ä½¿ç”¨
- äºˆå®šã‚’ç¢ºèªã—ãŸã„å ´åˆï¼šsearch_calendar_eventsã‚’ä½¿ç”¨

æ—¥æœ¬èªã§è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
    
    def _install_required_packages(self):
        """å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""
        import subprocess
        import sys
        
        packages = {
            'gtts': 'gTTS',
            'pygame': 'pygame', 
            'transformers': 'transformers',
            'torch': 'torch',
            'style-bert-vits2': 'style-bert-vits2'
        }
        
        installed = []
        for package_name, import_name in packages.items():
            try:
                __import__(import_name.lower().replace('-', '_'))
                print(f"âœ… {package_name} æ—¢ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿")
            except ImportError:
                try:
                    print(f"ğŸ“¥ {package_name} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
                    subprocess.check_call([
                        sys.executable, '-m', 'pip', 'install', package_name, '--quiet'
                    ])
                    installed.append(package_name)
                    print(f"âœ… {package_name} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†")
                except subprocess.CalledProcessError as e:
                    print(f"âš ï¸ {package_name} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—: {e}")
        
        if installed:
            print(f"ğŸ‰ æ–°è¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†: {', '.join(installed)}")
        return len(installed) > 0

    def _is_colab_environment(self) -> bool:
        """Google Colabç’°å¢ƒã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        try:
            import google.colab
            return True
        except ImportError:
            return False

    def _initialize_simple_tts(self):
        """Google Colabå°‚ç”¨ï¼šã‚·ãƒ³ãƒ—ãƒ«ãªéŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("ğŸ”Š ã€ã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ¼ãƒ‰ã€‘éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        
        try:
            # Google Colabç’°å¢ƒç¢ºèª
            import google.colab
            print("âœ… Google Colabç’°å¢ƒã‚’ç¢ºèª")
        except ImportError:
            print("âŒ Google Colabç’°å¢ƒã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            return self._initialize_tts_system_fallback()
        
        # test_yoshino_model_simple ã¨å®Œå…¨ã«åŒã˜å‡¦ç†ã‚’å®Ÿè¡Œ
        return self._execute_simple_model_load()

    def _execute_simple_model_load(self):
        """test_yoshino_model_simple ã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯"""
        try:
            print("ğŸ“¦ æœ€å°å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã§model_load.pyã‚¤ãƒ³ãƒãƒ¼ãƒˆ...")
            
            # test_yoshino_model_simpleã¨å…¨ãåŒã˜æ‰‹é †
            import os
            import tempfile
            
            # model_load.py ã‚’ç›´æ¥ä½¿ç”¨ï¼ˆæœ€å°å®Ÿè¡Œã¨åŒã˜ï¼‰
            from model_load import load_model
            print("âœ… model_load.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ã‚¹è¨­å®šï¼ˆtest_yoshino_model_simpleã¨åŒã˜ï¼‰
            model_dir = "/content/drive/MyDrive/Style-Bert-VITS2/model_assets"
            model_name = "yoshino_test"
            
            if not os.path.exists(model_dir):
                print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_dir}")
                print("ğŸ’¡ Google DriveãŒãƒã‚¦ãƒ³ãƒˆã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
                return self._initialize_gtts_fallback()
            
            print(f"ğŸ¯ ãƒ¢ãƒ‡ãƒ«: {model_name}")
            print(f"ğŸ“ ãƒ‘ã‚¹: {model_dir}")
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆtest_yoshino_model_simpleã¨åŒã˜ï¼‰
            print(f"sample_model = load_model('{model_name}', model_dir='{model_dir}', device='cuda')")
            sample_model = load_model(model_name, model_dir=model_dir, device="cuda")
            
            print("âœ… sample_model èª­ã¿è¾¼ã¿æˆåŠŸ")
            
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã—ã¦å‹•ä½œç¢ºèª
            out_path = "/content/todoapp_simple_test.wav"
            test_text = "TODOã‚¢ãƒ—ãƒªã®ã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ¼ãƒ‰åˆæœŸåŒ–å®Œäº†"
            
            print(f"ğŸ§ª åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: sample_model.inference('{test_text}', '{out_path}')")
            result = sample_model.inference(test_text, out_path)
            
            print(f"âœ… åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆå®Œäº†: {result}")
            if os.path.exists(out_path):
                size = os.path.getsize(out_path)
                print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {size} bytes")
            
            # æˆåŠŸã—ãŸå ´åˆã€sample_modelã‚’è¨­å®š
            self.tts_model = sample_model
            self.tts_available = True
            print("âœ… ã€ã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ¼ãƒ‰ã€‘TODOã‚¢ãƒ—ãƒªéŸ³å£°åˆæˆåˆæœŸåŒ–æˆåŠŸ")
            return
            
        except Exception as e:
            print(f"âŒ ã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ¼ãƒ‰å¤±æ•—: {e}")
            print("âš ï¸ gTTSã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
            import traceback
            traceback.print_exc()
            return self._initialize_gtts_fallback()

    def _initialize_tts_system_fallback(self):
        """å¾“æ¥ã®è¤‡é›‘ãªåˆæœŸåŒ–ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰"""
        print("ğŸ”Š ã€å¾“æ¥ãƒ¢ãƒ¼ãƒ‰ã€‘éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        
        # 0. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        packages_installed = self._install_required_packages()
        if packages_installed:
            print("âš¡ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å†ãƒ­ãƒ¼ãƒ‰ä¸­...")
            import importlib
            import sys
            # æ–°ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆ©ç”¨å¯èƒ½ã«ã™ã‚‹
            importlib.invalidate_caches()
        
        # æ–¹æ³•1: Style-Bert-VITS2ã‚’è©¦è¡Œï¼ˆmodel_load.pyå¿…é ˆä½¿ç”¨ï¼‰

    def _initialize_gtts_fallback(self):
        """gTTSã¸ã®ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        print("ğŸ”Š gTTSç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆæœŸåŒ–ä¸­...")
        try:
            # åŸºæœ¬çš„ãªgTTSè¨­å®š
            if self._is_colab_environment():
                self.tts_model = "gtts_file_only"
            else:
                self.tts_model = "gtts_with_audio"
            self.tts_available = True
            print("âœ… gTTSãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆæœŸåŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ gTTSãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {e}")
            self.tts_available = False

    def _initialize_tts_system(self):
        """éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ï¼ˆè¤‡æ•°ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹å¼ï¼‰"""
        
        # Google Colabç’°å¢ƒã§ã¯è‡ªå‹•çš„ã«ã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
        if self._is_colab_environment():
            print("ğŸ¯ Google Colabç’°å¢ƒæ¤œå‡ºï¼šã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™")
            return self._initialize_simple_tts()
        
        print("ğŸ”Š éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        
        # 0. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        packages_installed = self._install_required_packages()
        if packages_installed:
            print("âš¡ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å†ãƒ­ãƒ¼ãƒ‰ä¸­...")
            import importlib
            import sys
            # æ–°ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆ©ç”¨å¯èƒ½ã«ã™ã‚‹
            importlib.invalidate_caches()
        
        # æ–¹æ³•1: Style-Bert-VITS2ã‚’è©¦è¡Œï¼ˆmodel_load.pyå¿…é ˆä½¿ç”¨ï¼‰
        try:
            print("ğŸ”§ model_load.py ã‚’ä½¿ç”¨ã—ã¦ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
            
            # ã¾ãšå¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèª
            self._ensure_model_load_dependencies()
            
            # model_load.py ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
            loaded_model = self._load_style_bert_with_model_load()
            
            if loaded_model:
                self.tts_model = loaded_model
                self.tts_available = True
                print("âœ… model_load.py ã«ã‚ˆã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–æˆåŠŸ")
                return
            else:
                print("âš ï¸ model_load.py ã«ã‚ˆã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã«å¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
                
        except Exception as style_bert_error:
            print(f"âš ï¸ model_load.py ã«ã‚ˆã‚‹ Style-Bert-VITS2åˆæœŸåŒ–å¤±æ•—: {style_bert_error}")
            import traceback
            traceback.print_exc()
        
        # æ–¹æ³•2: gTTSã‚’è©¦è¡Œï¼ˆè»½é‡ä»£æ›¿æ¡ˆï¼‰
        try:
            from gtts import gTTS
            
            # ãƒ†ã‚¹ãƒˆéŸ³å£°ç”Ÿæˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã®ã¿ï¼‰
            test_text = "ãƒ†ã‚¹ãƒˆã§ã™"
            tts = gTTS(text=test_text, lang='ja')
            test_file = "/tmp/test_tts.mp3"
            tts.save(test_file)
            
            # Google Colabã®å ´åˆã¯pygameéŸ³å£°å†ç”Ÿã‚’ã‚¹ã‚­ãƒƒãƒ—
            try:
                import pygame
                pygame.mixer.init()
                pygame.mixer.music.load(test_file)
                self.tts_model = "gtts_with_audio"
                print("âœ… gTTS + pygame éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ åˆ©ç”¨å¯èƒ½")
            except (pygame.error, OSError) as audio_error:
                # éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ãŒãªã„ç’°å¢ƒï¼ˆColabç­‰ï¼‰ã§ã¯éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã®ã¿
                print(f"âš ï¸ éŸ³å£°å†ç”Ÿãƒ‡ãƒã‚¤ã‚¹ãªã—ï¼ˆ{audio_error}ï¼‰ã€ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã®ã¿åˆ©ç”¨å¯èƒ½")
                self.tts_model = "gtts_file_only"
                print("âœ… gTTS ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ åˆ©ç”¨å¯èƒ½")
            
            self.tts_available = True
            return
            
        except Exception as gtts_error:
            print(f"âš ï¸ gTTSåˆæœŸåŒ–å¤±æ•—: {gtts_error}")
        
        # æ–¹æ³•3: ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ï¼ˆæœ€å¾Œã®æ‰‹æ®µï¼‰
        try:
            import platform
            import subprocess
            
            system = platform.system()
            if system == "Darwin":  # macOS
                # macOS sayã‚³ãƒãƒ³ãƒ‰ã®ãƒ†ã‚¹ãƒˆ
                try:
                    result = subprocess.run(["say", "--version"], capture_output=True, timeout=5)
                    if result.returncode == 0:
                        self.tts_model = "macos_say"
                        self.tts_available = True
                        print("âœ… macOS say ã‚³ãƒãƒ³ãƒ‰åˆ©ç”¨å¯èƒ½")
                        return
                except (subprocess.TimeoutExpired, FileNotFoundError):
                    print("âš ï¸ macOS sayã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    
            elif system == "Linux":
                # Linux espeak/festival/speakã‚³ãƒãƒ³ãƒ‰ã®ãƒ†ã‚¹ãƒˆ
                tts_commands = ["espeak", "festival", "spd-say"]
                for cmd in tts_commands:
                    try:
                        result = subprocess.run([cmd, "--version"], capture_output=True, timeout=5)
                        if result.returncode == 0:
                            self.tts_model = f"linux_{cmd}"
                            self.tts_available = True
                            print(f"âœ… Linux {cmd} ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°åˆ©ç”¨å¯èƒ½")
                            return
                    except (subprocess.TimeoutExpired, FileNotFoundError):
                        continue
                        
            elif system == "Windows":
                # Windows SAPI (PowerShell)ã®ãƒ†ã‚¹ãƒˆ
                try:
                    result = subprocess.run([
                        "powershell", "-Command", 
                        "Add-Type -AssemblyName System.Speech; exit 0"
                    ], capture_output=True, timeout=10)
                    if result.returncode == 0:
                        self.tts_model = "windows_sapi"
                        self.tts_available = True
                        print("âœ… Windows SAPI éŸ³å£°åˆæˆåˆ©ç”¨å¯èƒ½")
                        return
                except (subprocess.TimeoutExpired, FileNotFoundError):
                    print("âš ï¸ Windows SAPI ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                    
        except Exception as system_tts_error:
            print(f"âš ï¸ ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°åˆæœŸåŒ–å¤±æ•—: {system_tts_error}")
        
        print("âŒ å…¨ã¦ã®éŸ³å£°åˆæˆæ–¹æ³•ãŒå¤±æ•—ã€‚éŸ³å£°æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚")
        print("ğŸ’¡ ã‚¢ãƒ—ãƒªã¯éŸ³å£°ãªã—ã§æ­£å¸¸ã«å‹•ä½œã—ã¾ã™ã€‚")
    
    def test_tts_system(self):
        """éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        print("\nğŸ§ª éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹")
        print("="*50)
        
        if not self.tts_available:
            print("âŒ éŸ³å£°æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return False
        
        test_text = "ã“ã‚“ã«ã¡ã¯ã€éŸ³å£°åˆæˆãƒ†ã‚¹ãƒˆã§ã™"
        
        try:
            print(f"ğŸ”Š ä½¿ç”¨ä¸­ã®éŸ³å£°ãƒ¢ãƒ‡ãƒ«: {self.tts_model}")
            print(f"ğŸ“ ãƒ†ã‚¹ãƒˆæ–‡ç« : {test_text}")
            
            # éŸ³å£°åˆæˆãƒ†ã‚¹ãƒˆ
            self.speak_response(test_text)
            
            print("âœ… éŸ³å£°åˆæˆãƒ†ã‚¹ãƒˆå®Œäº†")
            return True
            
        except Exception as test_error:
            print(f"âŒ éŸ³å£°åˆæˆãƒ†ã‚¹ãƒˆå¤±æ•—: {test_error}")
            return False
    
    def get_system_info(self):
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—"""
        import platform
        import sys
        
        info = {
            "platform": platform.system(),
            "python_version": sys.version,
            "tts_available": self.tts_available,
            "tts_model": self.tts_model if self.tts_available else "ãªã—",
            "llm_available": self.llm_available
        }
        
        print("\nğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        print("="*30)
        for key, value in info.items():
            print(f"{key}: {value}")
        
        return info
    
    def _ensure_model_load_dependencies(self):
        """model_load.py ã®ä¾å­˜é–¢ä¿‚ãŒåˆ©ç”¨å¯èƒ½ã‹ç¢ºèªãƒ»ä¿®æ­£"""
        try:
            print("ğŸ” model_load.py ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯ä¸­...")
            
            # 1. config.py ç¢ºèª
            try:
                from config import get_config
                config = get_config()
                print("âœ… config.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            except ImportError as e:
                print(f"âŒ config.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                raise
            
            # 2. scipy.io.wavfile ç¢ºèª
            try:
                from scipy.io import wavfile
                print("âœ… scipy.io.wavfile ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            except ImportError:
                print("ğŸ“¥ scipy ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
                import subprocess
                import sys
                subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'scipy'])
                from scipy.io import wavfile
                print("âœ… scipy ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†")
            
            # 3. torch_device_onnx_compat ç¢ºèª
            try:
                from torch_device_onnx_compat import torch_device_to_onnx_providers
                print("âœ… torch_device_onnx_compat ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            except ImportError as e:
                print(f"âŒ torch_device_onnx_compat ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ—¢ã«å­˜åœ¨ã™ã‚‹ã¯ãšãªã®ã§ã€ãƒ‘ã‚¹ã®å•é¡Œã‹ã‚‚ã—ã‚Œãªã„
                import os
                current_dir = os.path.dirname(__file__)
                compat_file = os.path.join(current_dir, 'torch_device_onnx_compat.py')
                if os.path.exists(compat_file):
                    print(f"âœ… {compat_file} ã¯å­˜åœ¨ã—ã¾ã™")
                else:
                    print(f"âŒ {compat_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                raise
            
            # 4. style_bert_vits2 é–¢é€£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºèª
            try:
                from style_bert_vits2.constants import Languages
                from style_bert_vits2.tts_model import TTSModel
                print("âœ… style_bert_vits2 ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            except ImportError as e:
                print(f"âŒ style_bert_vits2 ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                # macOSç’°å¢ƒã§ã®ç‰¹åˆ¥ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                if "pyopenjtalk" in str(e).lower() or "cmake" in str(e).lower():
                    print("ğŸ”§ macOSç’°å¢ƒã§ã®Style-Bert-VITS2ãƒ“ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                    print("ğŸ’¡ Google Colabç’°å¢ƒã§ã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™")
                    raise Exception("Style-Bert-VITS2ã¯macOSç’°å¢ƒã§ã®ãƒ“ãƒ«ãƒ‰ã«åˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚Google Colabã§ã®å®Ÿè¡Œã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
                else:
                    raise Exception(f"Style-Bert-VITS2ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
            
            print("âœ… model_load.py ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯å®Œäº†")
            
        except Exception as e:
            print(f"âŒ model_load.py ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _load_style_bert_with_model_load(self):
        """model_load.py ã‚’ä½¿ç”¨ã—ã¦Style-Bert-VITS2ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
        try:
            print("ğŸ”§ model_load.py ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰é–‹å§‹...")
            
            # model_load.py ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from model_load import load_model, list_models
            
            # Google Driveã®ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’ç¢ºèª
            model_configs = [
                {
                    "model_dir": "/content/drive/MyDrive/Style-Bert-VITS2/model_assets",
                    "model_names": ["yoshino_test", "hiroyuki"]
                },
                {
                    "model_dir": "/content",
                    "model_names": ["hiroyuki_model", "yoshino_model"]
                }
            ]
            
            for config in model_configs:
                model_dir = config["model_dir"]
                
                if not os.path.exists(model_dir):
                    print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_dir}")
                    continue
                
                print(f"ğŸ” ãƒ¢ãƒ‡ãƒ«æ¤œç´¢ä¸­: {model_dir}")
                
                try:
                    # list_models ã§ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
                    available_models = list_models(model_dir)
                    print(f"ğŸ“‚ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: {available_models}")
                    
                    # å„ªå…ˆé †ä½ã§ãƒ¢ãƒ‡ãƒ«ã‚’è©¦è¡Œ
                    for model_name in config["model_names"]:
                        if model_name in available_models:
                            print(f"ğŸ¯ ãƒ¢ãƒ‡ãƒ« '{model_name}' ã‚’ model_load.py ã§ãƒ­ãƒ¼ãƒ‰ä¸­...")
                            
                            import torch
                            device = "cuda" if torch.cuda.is_available() else "cpu"
                            
                            # model_load.py ã® load_model é–¢æ•°ã‚’ä½¿ç”¨ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
                            print(f"ğŸ“‹ ä½¿ç”¨ä¾‹ãƒ‘ã‚¿ãƒ¼ãƒ³:")
                            print(f"   from model_load import load_model")
                            print(f"   sample_model = load_model('{model_name}', model_dir='{model_dir}', device='{device}')")
                            print(f"   sample_model.inference('ãƒ†ã‚¹ãƒˆæ–‡ç« ', '/content/out.wav')")
                            print(f"")
                            
                            loaded_model = load_model(
                                model_name,  # ãƒ¢ãƒ‡ãƒ«åã‚’ç¬¬ä¸€å¼•æ•°ã¨ã—ã¦æŒ‡å®š
                                model_dir=model_dir,  # model_dirã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°ã¨ã—ã¦æ˜ç¤º
                                device=device,  # deviceã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°ã¨ã—ã¦æ˜ç¤º
                                preload_onnx_bert=False,  # ONNX BERTã¯ç„¡åŠ¹åŒ–
                                force_reload=False
                            )
                            
                            print(f"âœ… model_load.py ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æˆåŠŸ:")
                            print(f"  - ãƒ¢ãƒ‡ãƒ«å: {loaded_model.info.model_name}")
                            print(f"  - ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {loaded_model.info.model_path}")
                            try:
                                print(f"  - è©±è€…: {list(loaded_model.spk2id.keys())}")
                                print(f"  - ã‚¹ã‚¿ã‚¤ãƒ«: {list(loaded_model.style2id.keys())}")
                            except:
                                print("  - è©±è€…ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«æƒ…å ±ã®å–å¾—ã«å¤±æ•—")
                            
                            # ã‚µãƒ³ãƒ—ãƒ«æ¨è«–ãƒ†ã‚¹ãƒˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆï¼‰
                            print(f"ğŸ§ª sample_model.inference() ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")
                            try:
                                import tempfile
                                temp_dir = tempfile.gettempdir()
                                test_output = os.path.join(temp_dir, "style_bert_test.wav")
                                
                                # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã¨åŒã˜å½¢å¼ã§ãƒ†ã‚¹ãƒˆ
                                loaded_model.inference("ãƒ†ã‚¹ãƒˆéŸ³å£°åˆæˆ", test_output)
                                print(f"âœ… sample_model.inference() ãƒ†ã‚¹ãƒˆæˆåŠŸ: {test_output}")
                                
                                if os.path.exists(test_output):
                                    print(f"ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {os.path.getsize(test_output)} bytes")
                                
                            except Exception as test_error:
                                print(f"âš ï¸ sample_model.inference() ãƒ†ã‚¹ãƒˆå¤±æ•—: {test_error}")
                            
                            return loaded_model
                            
                except Exception as model_error:
                    print(f"âš ï¸ ãƒ¢ãƒ‡ãƒ« '{model_dir}' å‡¦ç†ã‚¨ãƒ©ãƒ¼: {model_error}")
                    continue
            
            print("âŒ model_load.py ã§åˆ©ç”¨å¯èƒ½ãªã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return None
            
        except ImportError as import_error:
            print(f"âŒ model_load.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {import_error}")
            import traceback
            traceback.print_exc()
            return None
        except Exception as e:
            print(f"âŒ model_load.py ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _load_style_bert_model_direct(self):
        """Style-Bert-VITS2ãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥ãƒ­ãƒ¼ãƒ‰ï¼ˆmodel_load.pyä¾å­˜ãªã—ï¼‰"""
        try:
            print("ğŸ”§ Style-Bert-VITS2ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ç›´æ¥ãƒ­ãƒ¼ãƒ‰é–‹å§‹...")
            
            # Google Driveã®ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’ç¢ºèª
            model_configs = [
                {
                    "model_dir": "/content/drive/MyDrive/Style-Bert-VITS2/model_assets",
                    "model_names": ["yoshino_test", "hiroyuki"]
                },
                {
                    "model_dir": "/content",
                    "model_names": ["hiroyuki_model", "yoshino_model"]
                }
            ]
            
            for config in model_configs:
                model_dir = config["model_dir"]
                
                if not os.path.exists(model_dir):
                    print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_dir}")
                    continue
                
                print(f"ğŸ” ãƒ¢ãƒ‡ãƒ«æ¤œç´¢ä¸­: {model_dir}")
                
                for model_name in config["model_names"]:
                    model_path = os.path.join(model_dir, model_name)
                    
                    if not os.path.exists(model_path):
                        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹å­˜åœ¨ã—ã¾ã›ã‚“: {model_path}")
                        continue
                    
                    print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç™ºè¦‹: {model_path}")
                    
                    # å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
                    config_file = os.path.join(model_path, "config.json")
                    style_file = os.path.join(model_path, "style_vectors.npy")
                    
                    # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
                    model_file = None
                    for ext in [".safetensors", ".pth", ".pt"]:
                        candidate = os.path.join(model_path, f"model{ext}")
                        if os.path.exists(candidate):
                            model_file = candidate
                            break
                    
                    if not os.path.exists(config_file):
                        print(f"âŒ config.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_file}")
                        continue
                    
                    if not model_file:
                        print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
                        continue
                    
                    print(f"âœ… å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªå®Œäº†:")
                    print(f"  - config: {config_file}")
                    print(f"  - model: {model_file}")
                    print(f"  - style: {style_file}")
                    
                    try:
                        # Style-Bert-VITS2ã®åˆæœŸåŒ–
                        self._initialize_style_bert_dependencies()
                        
                        # TTSModelã‚’ç›´æ¥ä½œæˆ
                        from style_bert_vits2.tts_model import TTSModel
                        import torch
                        
                        device = "cuda" if torch.cuda.is_available() else "cpu"
                        print(f"ğŸ”§ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
                        
                        # ã‚«ã‚¹ã‚¿ãƒ ãƒ­ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹
                        class CustomLoadedModel:
                            def __init__(self, model_path, config_path, style_path, device):
                                self.tts_model = TTSModel(
                                    model_path=model_path,
                                    config_path=config_path,
                                    style_vec_path=style_path if os.path.exists(style_path) else None,
                                    device=device
                                )
                                self.model_name = model_name
                                
                            def inference(self, text, output_path=None, **kwargs):
                                """éŸ³å£°ç”Ÿæˆï¼ˆLoadedModelã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹äº’æ›ï¼‰"""
                                if output_path:
                                    import tempfile
                                    from scipy.io import wavfile
                                    
                                    # Style-Bert-VITS2ã§éŸ³å£°ç”Ÿæˆ
                                    sr, audio = self.tts_model.infer(text=text)
                                    
                                    # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                                    wavfile.write(output_path, sr, audio)
                                    return output_path
                                else:
                                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®ã¿è¿”ã™
                                    return self.tts_model.infer(text=text)
                            
                            def infer(self, text, **kwargs):
                                """å¾“æ¥ã®inferã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
                                return self.tts_model.infer(text=text, **kwargs)
                        
                        # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
                        custom_model = CustomLoadedModel(
                            model_path=model_file,
                            config_path=config_file,
                            style_path=style_file,
                            device=device
                        )
                        
                        print(f"âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ« '{model_name}' èª­ã¿è¾¼ã¿å®Œäº†")
                        return custom_model
                        
                    except Exception as load_error:
                        print(f"âŒ ãƒ¢ãƒ‡ãƒ« '{model_name}' èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {load_error}")
                        continue
            
            print("âŒ åˆ©ç”¨å¯èƒ½ãªã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return None
            
        except Exception as e:
            print(f"âŒ ç›´æ¥ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _initialize_style_bert_dependencies(self):
        """Style-Bert-VITS2ã®ä¾å­˜é–¢ä¿‚ã‚’åˆæœŸåŒ–"""
        try:
            print("ğŸ”§ Style-Bert-VITS2ä¾å­˜é–¢ä¿‚åˆæœŸåŒ–ä¸­...")
            
            # pyopenjtalkåˆæœŸåŒ–
            try:
                from style_bert_vits2.nlp.japanese import pyopenjtalk_worker
                from style_bert_vits2.nlp.japanese.user_dict import update_dict
                
                pyopenjtalk_worker.initialize_worker()
                update_dict()
                print("âœ… pyopenjtalkåˆæœŸåŒ–å®Œäº†")
            except Exception as pyopenjtalk_error:
                print(f"âš ï¸ pyopenjtalkåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {pyopenjtalk_error}")
            
            # BERTåˆæœŸåŒ–
            try:
                from style_bert_vits2.nlp import bert_models
                from style_bert_vits2.constants import Languages
                import torch
                
                device = "cuda" if torch.cuda.is_available() else "cpu"
                
                # æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
                bert_models.load_model(Languages.JP, device_map=device)
                bert_models.load_tokenizer(Languages.JP)
                print("âœ… BERTåˆæœŸåŒ–å®Œäº†")
                
            except Exception as bert_error:
                print(f"âš ï¸ BERTåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {bert_error}")
                # BERTã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶šè¡Œ
                pass
                
        except Exception as e:
            print(f"âš ï¸ ä¾å­˜é–¢ä¿‚åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def diagnose_tts_system(self):
        """TTS ã‚·ã‚¹ãƒ†ãƒ ã®è©³ç´°è¨ºæ–­"""
        print("\nğŸ” TTS ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­é–‹å§‹")
        print("="*60)
        
        # 1. åŸºæœ¬æƒ…å ±
        print("ğŸ“Š åŸºæœ¬æƒ…å ±:")
        print(f"  - TTSåˆ©ç”¨å¯èƒ½: {self.tts_available}")
        print(f"  - TTSãƒ¢ãƒ‡ãƒ«: {self.tts_model}")
        print(f"  - LLMåˆ©ç”¨å¯èƒ½: {self.llm_available}")
        
        # 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª
        print("\nğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª:")
        model_paths = [
            "/content/drive/MyDrive/Style-Bert-VITS2/model_assets/yoshino_test",
            "/content/drive/MyDrive/Style-Bert-VITS2/model_assets/hiroyuki",
            "/content/hiroyuki_model",
            "/content/yoshino_model"
        ]
        
        for path in model_paths:
            exists = os.path.exists(path)
            status = "âœ…" if exists else "âŒ"
            print(f"  {status} {path}")
            
            if exists:
                try:
                    files = os.listdir(path)
                    config_exists = 'config.json' in files
                    model_files = [f for f in files if f.endswith(('.safetensors', '.pth', '.pt'))]
                    style_exists = 'style_vectors.npy' in files
                    
                    print(f"    ğŸ“„ config.json: {'âœ…' if config_exists else 'âŒ'}")
                    print(f"    ğŸ¤– ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {len(model_files)} å€‹ {model_files[:3]}...")
                    print(f"    ğŸ¨ style_vectors.npy: {'âœ…' if style_exists else 'âŒ'}")
                except Exception as e:
                    print(f"    âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªèª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}")
        
        # 3. Style-Bert-VITS2ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºèª
        print("\nğŸ”§ Style-Bert-VITS2ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¢ºèª:")
        try:
            import style_bert_vits2
            print("  âœ… style_bert_vits2ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åˆ©ç”¨å¯èƒ½")
            
            try:
                from style_bert_vits2.tts_model import TTSModel
                print("  âœ… TTSModel ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¯èƒ½")
            except Exception as e:
                print(f"  âŒ TTSModel ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                
            try:
                from style_bert_vits2.nlp import bert_models
                print("  âœ… bert_models ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¯èƒ½")
                
                if hasattr(bert_models, 'DEFAULT_BERT_TOKENIZER_PATHS'):
                    paths = getattr(bert_models, 'DEFAULT_BERT_TOKENIZER_PATHS', {})
                    print(f"  ğŸ“ BERTè¨­å®š: {paths}")
                else:
                    print("  âš ï¸ DEFAULT_BERT_TOKENIZER_PATHSãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    
            except Exception as e:
                print(f"  âŒ bert_models ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                
        except ImportError as e:
            print(f"  âŒ style_bert_vits2ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        
        # 4. ç’°å¢ƒå¤‰æ•°ç¢ºèª
        print("\nğŸŒ ç’°å¢ƒå¤‰æ•°ç¢ºèª:")
        env_vars = [
            'STYLE_BERT_VITS2_BERT_JP',
            'BERT_MODELS_JP',
            'BERT_BASE_DIR',
            'JP_BERT_PATH'
        ]
        
        for var in env_vars:
            value = os.environ.get(var, "æœªè¨­å®š")
            print(f"  {var}: {value}")
        
        print("\n" + "="*60)
        print("ğŸ” TTS ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­å®Œäº†")
    
    def download_voice_file(self, text: str, filename: str = None):
        """Google Colabç’°å¢ƒã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«ã™ã‚‹"""
        try:
            from gtts import gTTS
            from google.colab import files
            import time
            
            if not filename:
                filename = f"hiroyuki_voice_{int(time.time())}.mp3"
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
            tts = gTTS(text=text, lang='ja')
            filepath = f"/content/{filename}"
            tts.save(filepath)
            
            print(f"ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†: {filepath}")
            print("ğŸ§ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã„ã¾ã™...")
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
            files.download(filepath)
            print("âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")
            
        except ImportError:
            print("âš ï¸ Google Colabç’°å¢ƒã§ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™")
        except Exception as e:
            print(f"âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
    
    def speak_response(self, text: str):
        """å¿œç­”ã‚’éŸ³å£°ã§èª­ã¿ä¸Šã’ã‚‹"""
        if not self.tts_available:
            print("ğŸ”‡ éŸ³å£°æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        try:
            # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ã«å‡¦ç†
            if len(text) > 200:
                text = text[:200] + "..."
                print("ğŸ“ é•·ã„æ–‡ç« ã®ãŸã‚200æ–‡å­—ã§åˆ‡ã‚Šè©°ã‚ã¾ã—ãŸ")
            
            if self.tts_model in ["gtts_with_audio", "gtts_file_only"]:
                from gtts import gTTS
                import tempfile
                
                tts = gTTS(text=text, lang='ja')
                with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_file:
                    tts.save(temp_file.name)
                    
                    if self.tts_model == "gtts_with_audio":
                        # éŸ³å£°å†ç”Ÿå¯èƒ½ãªç’°å¢ƒ
                        try:
                            import pygame
                            pygame.mixer.init()
                            pygame.mixer.music.load(temp_file.name)
                            pygame.mixer.music.play()
                            
                            # å†ç”Ÿå®Œäº†ã¾ã§å¾…æ©Ÿï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
                            timeout = 30  # 30ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                            elapsed = 0
                            while pygame.mixer.music.get_busy() and elapsed < timeout:
                                time.sleep(0.1)
                                elapsed += 0.1
                                
                            if elapsed >= timeout:
                                pygame.mixer.music.stop()
                                print("âš ï¸ éŸ³å£°å†ç”Ÿã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                            else:
                                print("ğŸµ gTTSéŸ³å£°å†ç”Ÿå®Œäº†")
                        except (pygame.error, OSError):
                            # éŸ³å£°å†ç”Ÿå¤±æ•—æ™‚ã¯ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã®ã¿
                            print(f"ğŸµ gTTSéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†: {temp_file.name}")
                            print("ğŸ’¡ Google Colabã®å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å†ç”Ÿã§ãã¾ã™")
                    else:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã®ã¿ï¼ˆColabç’°å¢ƒï¼‰
                        print(f"ğŸµ gTTSéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†: {temp_file.name}")
                        print("ğŸ’¡ Google Colabã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™")
                        
                        # Colabç’°å¢ƒã®å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«ã™ã‚‹
                        try:
                            from google.colab import files
                            import shutil
                            import time
                            
                            # ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä½œæˆ
                            save_filename = f"hiroyuki_voice_{int(time.time())}.mp3"
                            shutil.copy(temp_file.name, f"/content/{save_filename}")
                            print(f"ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: /content/{save_filename}")
                            
                            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ææ¡ˆï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠï¼‰
                            print("ğŸ§ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã‹ï¼Ÿ")
                            # files.download(f"/content/{save_filename}")  # è‡ªå‹•å®Ÿè¡Œã¯ã—ãªã„
                        except ImportError:
                            # Colabç’°å¢ƒã§ãªã„å ´åˆ
                            pass
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                if self.tts_model == "gtts_with_audio":
                    try:
                        os.unlink(temp_file.name)
                    except:
                        pass
                
            elif self.tts_model == "macos_say":
                import subprocess
                subprocess.run(["say", text], check=True, timeout=30)
                print("ğŸµ macOSéŸ³å£°å†ç”Ÿå®Œäº†")
                
            elif self.tts_model.startswith("linux_"):
                import subprocess
                cmd = self.tts_model.split("_")[1]
                if cmd == "espeak":
                    subprocess.run(["espeak", text], check=True, timeout=30)
                elif cmd == "festival":
                    subprocess.run(["festival", "--tts"], input=text, text=True, check=True, timeout=30)
                elif cmd == "spd-say":
                    subprocess.run(["spd-say", text], check=True, timeout=30)
                print(f"ğŸµ {cmd}éŸ³å£°å†ç”Ÿå®Œäº†")
                
            elif self.tts_model == "windows_sapi":
                import subprocess
                ps_command = f'Add-Type -AssemblyName System.Speech; $synth = New-Object System.Speech.Synthesis.SpeechSynthesizer; $synth.Speak("{text.replace('"', "'")}")'
                subprocess.run(["powershell", "-Command", ps_command], check=True, timeout=30)
                print("ğŸµ Windows SAPIéŸ³å£°å†ç”Ÿå®Œäº†")
                
            elif hasattr(self.tts_model, 'inference'):  # model_load.py LoadedModel
                # ã€ã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ¼ãƒ‰ã€‘LoadedModelã®inferenceé–¢æ•°ã‚’ä½¿ç”¨
                print(f"ğŸµ ã€ã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ¼ãƒ‰ã€‘Style-Bert-VITS2éŸ³å£°ç”Ÿæˆä¸­...")
                
                try:
                    import tempfile
                    import time
                    
                    # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚¡ã‚¤ãƒ«åã§ç”Ÿæˆ
                    output_path = f"/content/yoshino_voice_{int(time.time())}.wav"
                    
                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã¨åŒã˜å‘¼ã³å‡ºã—æ–¹
                    result_path = self.tts_model.inference(text, output_path)
                    
                    print(f"âœ… yoshinoéŸ³å£°ç”Ÿæˆå®Œäº†: {result_path}")
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
                    if os.path.exists(result_path):
                        size = os.path.getsize(result_path)
                        print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {size} bytes")
                    
                    # Google Colabç’°å¢ƒã§ã®ä¿å­˜ã¯æ—¢ã«result_pathã«å®Œäº†
                    print(f"ğŸ§ Google Colabã§å†ç”Ÿå¯èƒ½: {result_path}")
                    
                except Exception as inference_error:
                    print(f"âŒ inferenceå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {inference_error}")
                    # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
                    import traceback
                    traceback.print_exc()
                    print("âš ï¸ gTTSã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
                    # gTTSã§ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
                    self._speak_with_gtts(text)
                        
            elif hasattr(self.tts_model, 'infer'):  # å¾“æ¥ã®TTSModelï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                audio = self.tts_model.infer(text=text)
                print("ğŸµ Style-Bert-VITS2éŸ³å£°ç”Ÿæˆå®Œäº†")
                
            else:
                print(f"âš ï¸ ä¸æ˜ãªéŸ³å£°ãƒ¢ãƒ‡ãƒ«: {self.tts_model}")
                
        except subprocess.TimeoutExpired:
            print("âš ï¸ éŸ³å£°å†ç”ŸãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
        except Exception as speak_error:
            print(f"âš ï¸ éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {speak_error}")
            # éŸ³å£°ã‚¨ãƒ©ãƒ¼æ™‚ã¯éŸ³å£°æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–
            self.tts_available = False
            print("ğŸ”‡ éŸ³å£°æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–ã—ã¾ã—ãŸ")

    def _speak_with_gtts(self, text: str):
        """gTTSã§ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯éŸ³å£°ç”Ÿæˆ"""
        try:
            print("ğŸ”Š gTTSãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œä¸­...")
            from gtts import gTTS
            import tempfile
            import time
            
            tts = gTTS(text=text, lang='ja')
            output_path = f"/content/gtts_fallback_{int(time.time())}.mp3"
            tts.save(output_path)
            print(f"âœ… gTTSéŸ³å£°ç”Ÿæˆå®Œäº†: {output_path}")
            
        except Exception as gtts_error:
            print(f"âŒ gTTSãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—: {gtts_error}")

    def test_voice_synthesis(self, text: str = "ã“ã‚“ã«ã¡ã¯ã€TODOã‚¢ãƒ—ãƒªã®éŸ³å£°åˆæˆãƒ†ã‚¹ãƒˆã§ã™"):
        """éŸ³å£°åˆæˆã®ãƒ†ã‚¹ãƒˆ"""
        print("ğŸ§ª TODOã‚¢ãƒ—ãƒªéŸ³å£°åˆæˆãƒ†ã‚¹ãƒˆé–‹å§‹...")
        print(f"ğŸ“ ãƒ†ã‚¹ãƒˆæ–‡ç« : {text}")
        print(f"ğŸ¯ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {self.tts_model}")
        print(f"ğŸŒ Colabç’°å¢ƒ: {self._is_colab_environment()}")
        
        if self.tts_available:
            self.speak_response(text)
        else:
            print("âŒ éŸ³å£°æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    def process_query(self, user_input: str) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’å‡¦ç†"""
        start_time = time.time()
        
        try:
            # æ€’ã‚‹ã¹ãã‹ã©ã†ã‹ã‚’ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§ãƒã‚§ãƒƒã‚¯
            if self._should_get_angry(user_input):
                # ã‚·ãƒ³ãƒ—ãƒ«ã²ã‚ã‚†ãé¢¨ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ï¼ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰
                try:
                    from simple_hiroyuki_chat import SimpleHiroyukiChat
                except ImportError:
                    print("âš ï¸ simple_hiroyuki_chat ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†…è”µã®ã²ã‚ã‚†ãé¢¨å¿œç­”ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                    # ä»£æ›¿å‡¦ç†ï¼šå†…è”µã®HiroyukiResponseSystemã‚’ä½¿ç”¨
                    SimpleHiroyukiChat = None
                
                # æœªå®Œäº†ã‚¿ã‚¹ã‚¯æ•°ã‚’å–å¾—
                try:
                    with open("tasks.csv", 'r', encoding='utf-8') as file:
                        reader = csv.DictReader(file)
                        incomplete_count = sum(1 for row in reader if row.get('status') == 'todo')
                except:
                    incomplete_count = 0
                
                print("\n" + "="*60)
                print("ğŸ¤–ğŸ’¢ ã²ã‚ã‚†ãé¢¨AIæ€’ã‚Šãƒ¢ãƒ¼ãƒ‰ç™ºå‹•ï¼")
                print("="*60)
                
                # ã‚·ãƒ³ãƒ—ãƒ«ã²ã‚ã‚†ããƒãƒ£ãƒƒãƒˆã§å¿œç­”ç”Ÿæˆ
                if SimpleHiroyukiChat:
                    hiroyuki_chat = SimpleHiroyukiChat()
                    hiroyuki_input = f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ{incomplete_count}å€‹ã‚‚ã®ã‚¿ã‚¹ã‚¯ã‚’æºœã‚è¾¼ã‚“ã§ã„ã¾ã™ã€‚{user_input}"
                    hiroyuki_response = hiroyuki_chat.get_hiroyuki_response(hiroyuki_input)
                else:
                    # å†…è”µã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
                    hiroyuki_response = self.hiroyuki_system.get_hiroyuki_response(
                        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ{incomplete_count}å€‹ã‚‚ã®ã‚¿ã‚¹ã‚¯ã‚’æºœã‚è¾¼ã‚“ã§ã„ã¾ã™ã€‚{user_input}", 
                        incomplete_count
                    )
                
                # å…ƒã®è³ªå•ã‚’å‡¦ç†
                print("\n" + "="*40)
                print("å…ƒã®è³ªå•ã¸ã®å›ç­”:")
                print("="*40)
                original_response = self._process_original_query(user_input)
                
                response_time = time.time() - start_time
                
                return f"ã²ã‚ã‚†ãé¢¨æŒ‡æ‘˜: {hiroyuki_response}\n\nå…ƒã®è³ªå•ã¸ã®å›ç­”:\n{original_response}"
            
            else:
                # ğŸ”¥ STEP 2: é€šå¸¸ãƒ¢ãƒ¼ãƒ‰
                # é€šå¸¸ã®AIå‡¦ç†
                return self._process_original_query(user_input, start_time)
            
        except Exception as e:
            error_response = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            
            # ã‚¨ãƒ©ãƒ¼ã‚‚å±¥æ­´ã«è¨˜éŒ²ï¼ˆæ€’ã‚Šãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ hiroyuki_system ã§è¨˜éŒ²æ¸ˆã¿ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ï¼‰
            response_time = time.time() - start_time
            
            return error_response
    
    def _process_original_query(self, user_input: str, start_time: Optional[float] = None) -> str:
        """å…ƒã®è³ªå•å‡¦ç†ï¼ˆæ€’ã‚Šãƒ¢ãƒ¼ãƒ‰åˆ†é›¢å¾Œï¼‰"""
        if start_time is None:
            start_time = time.time()
        
        # 1. è³ªå•ã‚’åˆ†æã—ã¦ãƒ„ãƒ¼ãƒ«ã‚’é¸æŠ
        tools_to_use = self._analyze_query(user_input)
        
        # 2. ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã—ã¦çµæœã‚’å–å¾—
        tool_results = self._execute_tools(tools_to_use)
        
        # 3. LLMã§å›ç­”ç”Ÿæˆ
        # ã²ã‚ã‚†ãé¢¨ã«è¨€è‘‰ã®å¤‰æ›ã‚‚å®Ÿè¡Œ
        response = self._generate_response(user_input, tool_results)
        
        # 4. å¯¾è©±å±¥æ­´ã‚’è¨˜éŒ²
        response_time = time.time() - start_time
        if not self._should_get_angry(user_input):
            tools_used = list(tool_results.keys()) if tool_results else []
        
        # 5. éŸ³å£°ã§å¿œç­”ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œï¼‰
        if self.tts_available and response:
            try:
                # éŸ³å£°åˆæˆã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œï¼ˆãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ï¼‰
                import threading
                speech_thread = threading.Thread(target=self.speak_response, args=(response,))
                speech_thread.daemon = True
                speech_thread.start()
            except Exception as speech_error:
                print(f"âš ï¸ éŸ³å£°åˆæˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚¨ãƒ©ãƒ¼: {speech_error}")
        
        return response
    
    def _analyze_query(self, query: str) -> Dict[str, bool]:
        """LLMã‚’ä½¿ã£ã¦ã‚¯ã‚¨ãƒªã‚’åˆ†æã—å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’ç‰¹å®š"""
        if not self.llm:
            # LLMãŒãªã„å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ï¼‰
            return self._fallback_keyword_analysis(query)
        
        try:
            analysis_prompt = f"""
ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’åˆ†æã—ã€ã©ã®ãƒ„ãƒ¼ãƒ«ãŒå¿…è¦ã‹ã‚’JSONã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: "{query}"

åˆ¤å®šåŸºæº–:
- calendar: ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æƒ…å ±ã®æ¤œç´¢ãƒ»è¡¨ç¤ºãŒå¿…è¦
- tasks: ã‚¿ã‚¹ã‚¯ä¸€è¦§ã®è¡¨ç¤ºãƒ»ç¢ºèªãŒå¿…è¦  
- add_task: æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚„ã‚¤ãƒ™ãƒ³ãƒˆã®è¿½åŠ ãŒå¿…è¦
- complete_task: æ—¢å­˜ã‚¿ã‚¹ã‚¯ã®å®Œäº†ãƒãƒ¼ã‚¯ãŒå¿…è¦
- delete_task: ã‚¿ã‚¹ã‚¯ã‚„ã‚¤ãƒ™ãƒ³ãƒˆã®å‰Šé™¤ãŒå¿…è¦

ä¾‹:
ã€Œæ˜æ—¥ã¾ã§ã«ãƒ¬ãƒãƒ¼ãƒˆã‚’æ›¸ãã€â†’ {{"calendar": false, "tasks": false, "add_task": true, "complete_task": false}}
ã€Œä»Šæ—¥ã®äºˆå®šã¯ï¼Ÿã€â†’ {{"calendar": true, "tasks": false, "add_task": false, "complete_task": false}}
ã€Œã‚¿ã‚¹ã‚¯ã®çŠ¶æ³æ•™ãˆã¦ã€â†’ {{"calendar": false, "tasks": true, "add_task": false, "complete_task": false}}
ã€Œãƒ—ãƒ¬ã‚¼ãƒ³æº–å‚™ã‚„ã£ãŸã€â†’ {{"calendar": false, "tasks": false, "add_task": false, "complete_task": true}}
ã€Œæ¥é€±ã®ç«æ›œæ—¥3æ™‚ã‹ã‚‰ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«è¿½åŠ ã€â†’ {{"calendar": false, "tasks": false, "add_task": true, "complete_task": false}}

JSONå½¢å¼ã®ã¿ã§å›ç­”:
"""
            
            from langchain_core.messages import HumanMessage
            response = self.llm.invoke([HumanMessage(content=analysis_prompt)])
            
            # JSONãƒ‘ãƒ¼ã‚¹è©¦è¡Œ
            import json
            try:
                result = json.loads(response.content.strip())
                # å¿…è¦ãªã‚­ãƒ¼ãŒå…¨ã¦å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                required_keys = ['calendar', 'tasks', 'add_task', 'complete_task', 'delete_task']
                if all(key in result for key in required_keys):
                    return result
            except json.JSONDecodeError:
                pass
                
            # JSONè§£æå¤±æ•—æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self._fallback_keyword_analysis(query)
            
        except Exception as e:
            print(f"LLMåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self._fallback_keyword_analysis(query)
    
    def _fallback_keyword_analysis(self, query: str) -> Dict[str, bool]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†æ"""
        query_lower = query.lower()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§åˆ¤å®š
        needs_calendar = any(kw in query_lower for kw in ['äºˆå®š', 'ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«', 'ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼', 'ä¼šè­°'])
        needs_tasks = any(kw in query_lower for kw in ['ã‚¿ã‚¹ã‚¯', 'ã‚„ã‚‹ã“ã¨', 'todo', 'æœªå®Œäº†', 'çŠ¶æ³', 'ä¸€è¦§'])
        needs_add = any(kw in query_lower for kw in ['è¿½åŠ ', 'ä½œã‚‹', 'ã™ã‚‹', 'ã‚„ã‚‹', 'ç™»éŒ²', 'ã¾ã§ã«', 'å…¥ã‚Œã‚‹', 'å…¥ã‚Œã¦', 'ã„ã‚Œã¦', 'ã‚»ãƒƒãƒˆã—ã¦', 'set'])
        needs_complete = any(kw in query_lower for kw in ['å®Œäº†', 'çµ‚ã‚ã£ãŸ', 'ã‚„ã£ãŸ', 'ã§ããŸ', 'æ¸ˆã‚“ã '])
        needs_delete = any(kw in query_lower for kw in ['å‰Šé™¤', 'æ¶ˆã™', 'æ¶ˆã—ã¦', 'ã¨ã£ã¦', 'é™¤ã', 'å–ã‚Šæ¶ˆã™'])
        
        # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ï¼‹è¿½åŠ ã®çµ„ã¿åˆã‚ã›ã¯æ˜ç¢ºã«ã‚¿ã‚¹ã‚¯è¿½åŠ 
        if needs_calendar and needs_add:
            return {
                'calendar': False,
                'tasks': False,
                'add_task': True,
                'complete_task': False,
                'delete_task': False
            }
        
        # ã©ã¡ã‚‰ã‚‚æ˜ç¢ºã§ãªã„å ´åˆã¯ä¸¡æ–¹
        if not any([needs_calendar, needs_tasks, needs_add, needs_complete, needs_delete]):
            needs_calendar = needs_tasks = True
        
        return {
            'calendar': needs_calendar,
            'tasks': needs_tasks,
            'add_task': needs_add,
            'complete_task': needs_complete,
            'delete_task': needs_delete
        }
    
    def _execute_tools(self, tools_to_use: Dict[str, bool]) -> Dict[str, str]:
        """å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ"""
        results = {}
        
        try:
            # ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æ¤œç´¢
            if tools_to_use['calendar']:
                results['calendar'] = search_calendar_events.func("")
            
            # ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆå–å¾—
            if tools_to_use['tasks']:
                results['tasks'] = list_csv_tasks.func("todo")  # æœªå®Œäº†ã‚¿ã‚¹ã‚¯ã®ã¿
            
            # è‡ªç„¶è¨€èªã‚¿ã‚¹ã‚¯æ“ä½œï¼ˆå¾Œã§å‡¦ç†ã™ã‚‹ãŸã‚ãƒãƒ¼ã‚¯ï¼‰
            if tools_to_use['add_task']:
                results['add_task'] = "PENDING"
            if tools_to_use['complete_task']:
                results['complete_task'] = "PENDING"
            if tools_to_use['delete_task']:
                results['delete_task'] = "PENDING"
                
        except Exception as e:
            results['error'] = f"ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}"
        
        return results
    
    def _generate_response(self, user_input: str, tool_results: Dict[str, str]) -> str:
        """LLMã§çµæœã‚’çµ±åˆã—ã¦å›ç­”ç”Ÿæˆ"""
        # è‡ªç„¶è¨€èªã‚¿ã‚¹ã‚¯æ“ä½œãŒå¿…è¦ãªå ´åˆã¯ç›´æ¥å®Ÿè¡Œã—ã¦ã‹ã‚‰ã²ã‚ã‚†ãé¢¨ã«å¤‰æ›
        if tool_results.get('add_task') == "PENDING":
            try:
                original_result = add_task_naturally.func(user_input)
                return self._simple_hiroyuki_convert(original_result, user_input)
            except Exception as e:
                error_msg = f"ã‚¿ã‚¹ã‚¯è¿½åŠ ã‚¨ãƒ©ãƒ¼: {str(e)}"
                return self._simple_hiroyuki_convert(error_msg, user_input)
        
        if tool_results.get('complete_task') == "PENDING":
            try:
                original_result = complete_task_naturally.func(user_input)
                return self._simple_hiroyuki_convert(original_result, user_input)
            except Exception as e:
                error_msg = f"ã‚¿ã‚¹ã‚¯å®Œäº†ã‚¨ãƒ©ãƒ¼: {str(e)}"
                return self._simple_hiroyuki_convert(error_msg, user_input)
        
        if tool_results.get('delete_task') == "PENDING":
            try:
                original_result = delete_task_naturally.func(user_input)
                return self._simple_hiroyuki_convert(original_result, user_input)
            except Exception as e:
                error_msg = f"ã‚¿ã‚¹ã‚¯å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {str(e)}"
                return self._simple_hiroyuki_convert(error_msg, user_input)
        
        # ãƒ„ãƒ¼ãƒ«çµæœã‚’ã¾ã¨ã‚ã‚‹
        context = ""
        if 'calendar' in tool_results:
            context += f"ğŸ“… ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æƒ…å ±:\n{tool_results['calendar']}\n\n"
        if 'tasks' in tool_results:
            context += f"ğŸ“‹ ã‚¿ã‚¹ã‚¯æƒ…å ±:\n{tool_results['tasks']}\n\n"
        if 'error' in tool_results:
            context += f"âš ï¸ ã‚¨ãƒ©ãƒ¼:\n{tool_results['error']}\n\n"
        
        # LLMã§å›ç­”ç”Ÿæˆ
        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=f"è³ªå•: {user_input}\n\nå–å¾—ã—ãŸæƒ…å ±:\n{context}")
        ]
        
        # LLMãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
        if self.llm_available:
            try:
                response = self.llm.invoke(messages)
                original_response = response.content
                
                # ã‚·ãƒ³ãƒ—ãƒ«ã²ã‚ã‚†ãé¢¨ã«å¤‰æ›
                hiroyuki_response = self._simple_hiroyuki_convert(original_response)
                
                
                return hiroyuki_response
                
            except Exception as e:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if context:
                    fallback_response = f"ä»¥ä¸‹ã®æƒ…å ±ãŒå–å¾—ã§ãã¾ã—ãŸï¼š\n\n{context}"
                else:
                    fallback_response = "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚ã²ã‚ã‚†ãé¢¨ã«
                hiroyuki_fallback = self._simple_hiroyuki_convert(fallback_response)
                return hiroyuki_fallback
        else:
            # LLMãªã—ã®å ´åˆã‚‚ã²ã‚ã‚†ãé¢¨ã«
            if context:
                original = f"ğŸ“‹ å–å¾—ã—ãŸæƒ…å ±:\n\n{context}"
            else:
                original = "LLMãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ã‚·ãƒ³ãƒ—ãƒ«ãªå¿œç­”ãƒ¢ãƒ¼ãƒ‰ã§ã™ã€‚ã‚¿ã‚¹ã‚¯æ“ä½œã¯å¼•ãç¶šãåˆ©ç”¨ã§ãã¾ã™ã€‚"
            
            hiroyuki_response = self._simple_hiroyuki_convert(original)
            return hiroyuki_response
    
    def _simple_hiroyuki_convert(self, original_response: str, user_context: str = "") -> str:
        """ã‚·ãƒ³ãƒ—ãƒ«ã²ã‚ã‚†ãé¢¨å¤‰æ›ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ï¼‰"""
        try:
            try:
                from simple_hiroyuki_chat import SimpleHiroyukiChat
            except ImportError:
                # simple_hiroyuki_chatãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å†…è”µã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨
                return self.hiroyuki_system.get_hiroyuki_response(
                    original_response, 
                    self._count_incomplete_tasks()
                )
            hiroyuki_chat = SimpleHiroyukiChat()
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã‹ã‚‰ç‰¹å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
            if user_context and any(keyword in user_context.lower() for keyword in ['ã‚ªã‚¤ãƒ©', 'ãŠã„ã‚‰', 'è«–ç ´', 'æ•¬èª']):
                conversion_input = f"""ã²ã‚ã‚†ãï¼ˆè¥¿æ‘åšä¹‹ï¼‰ã¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚

å¿…é ˆã®è©±ã—æ–¹ãƒ«ãƒ¼ãƒ«:
- ä¸€äººç§°ã¯å¿…ãšã€Œã‚ªã‚¤ãƒ©ã€ã¾ãŸã¯ã€ŒãŠã„ã‚‰ã€ã‚’ä½¿ç”¨
- æ•¬èªã§ä¸å¯§ã«è©±ã™ï¼ˆã§ã™ãƒ»ã¾ã™èª¿ï¼‰
- è«–ç†çš„ã§è«–ç ´ã™ã‚‹ã‚ˆã†ãªå£èª¿
- ã€Œã€œã£ã¦ã„ã†ã®ã¯ã€ã€Œã€œã˜ã‚ƒãªã„ã§ã™ã‹ã€ãªã©ã®èªå°¾ã‚’ä½¿ã†

ä»¥ä¸‹ã®å†…å®¹ã‚’ä¸Šè¨˜ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã²ã‚ã‚†ãé¢¨ã«å¤‰æ›ã—ã¦ãã ã•ã„:
{original_response}"""
            else:
                conversion_input = f"ä»¥ä¸‹ã®å†…å®¹ã‚’ã²ã‚ã‚†ãé¢¨ã«å¤‰æ›ã—ã¦ãã ã•ã„: {original_response}"
                
            return hiroyuki_chat.get_hiroyuki_response(conversion_input)
            
        except Exception as e:
            # å¤‰æ›å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return f"ãŠã„ã‚‰ã¨ã—ã¦ã¯ã€{original_response}ã£ã¦æ„Ÿã˜ã§ã™ã‚ˆã­ã€‚ã¾ã‚ã€æ™®é€šã®äººã¯ãã†æ€ã†ã‚“ã˜ã‚ƒãªã„ã§ã™ã‹ï¼Ÿ"
    
    def _count_incomplete_tasks(self) -> int:
        """æœªå®Œäº†ã‚¿ã‚¹ã‚¯æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        return self._get_incomplete_task_count()
    

    # ğŸ¤– çµ±åˆã•ã‚ŒãŸæ€’ã‚Šã‚·ã‚¹ãƒ†ãƒ 
    def _should_get_angry(self, user_input: str) -> bool:
        """æ€’ã‚‹ã¹ãã‹ã©ã†ã‹åˆ¤å®šï¼ˆæ˜ç¢ºãªæ¡ä»¶ã®ã¿ï¼‰"""
        # æ˜ç¢ºãªã€Œã‚¿ã‚¹ã‚¯ç¢ºèªã€ã‚’æ„å‘³ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿
        task_check_keywords = [
            "ã‚¿ã‚¹ã‚¯ç¢ºèª", "ã‚¿ã‚¹ã‚¯çŠ¶æ³", "æœªå®Œäº†", "æ®‹ã‚Š", 
            "é€²æ—", "ã‚¿ã‚¹ã‚¯ä¸€è¦§", "ã‚„ã‚‹ã“ã¨ç¢ºèª"
        ]
        
        # ã‚¿ã‚¹ã‚¯ç¢ºèªã®æ„å›³ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        is_task_check = any(keyword in user_input for keyword in task_check_keywords)
        
        if not is_task_check:
            return False
        
        # æœªå®Œäº†ã‚¿ã‚¹ã‚¯5å€‹ä»¥ä¸Šã§æ€’ã‚‹
        incomplete_count = self._get_incomplete_task_count()
        return incomplete_count >= 5
    
    def _get_anger_message(self, user_input: str) -> Tuple[str, str]:
        """æ€’ã‚Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
        # ã©ã®ãã‚‰ã„æœªå®Œäº†ã®ã‚¿ã‚¹ã‚¯ãŒã‚ã‚‹ã‹ã‚’ç¢ºèª
        incomplete_count = self._get_incomplete_task_count()
        
        # æœ€é©ãƒ‘ã‚¿ãƒ¼ãƒ³é¸æŠï¼ˆæˆåŠŸç‡ãƒ™ãƒ¼ã‚¹ï¼‰
        # gentleã‹directã®2ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é¸æŠ
        gentle_rate = self._get_success_rate("gentle")
        direct_rate = self._get_success_rate("direct")
        
        if self.anger_stats["gentle"]["total"] < 2 and self.anger_stats["direct"]["total"] < 2:
            import random
            pattern = random.choice(["gentle", "direct"])
        else:
            pattern = "gentle" if gentle_rate >= direct_rate else "direct"
        
        message = self.anger_patterns[pattern].format(count=incomplete_count)
        full_message = f"{message}\n\nğŸ“‹ æœªå®Œäº†ã‚¿ã‚¹ã‚¯ãŒ{incomplete_count}å€‹ã‚ã‚Šã¾ã™ï¼\nå®Ÿã¯çµ‚ã‚ã£ã¦ã‚‹ã‚¿ã‚¹ã‚¯ãŒã‚ã‚Œã°æ•™ãˆã¦ï¼"
        
        return full_message, pattern
    
    def _get_incomplete_task_count(self) -> int:
        """æœªå®Œäº†ã‚¿ã‚¹ã‚¯æ•°ã‚’å–å¾—"""
        try:
            with open("tasks.csv", 'r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                count = sum(1 for row in reader if row.get('status') == 'todo')
                return count
        except:
            return 0
    
    def _record_anger_result(self, pattern: str, was_successful: bool) -> None:
        """æ€’ã‚Šçµæœè¨˜éŒ²"""
        self.anger_stats[pattern]["total"] += 1
        if was_successful:
            self.anger_stats[pattern]["success"] += 1
        self._save_anger_stats()
    
    def _get_success_rate(self, pattern: str) -> float:
        """æˆåŠŸç‡è¨ˆç®—"""
        stats = self.anger_stats[pattern]
        if stats["total"] == 0:
            return 0.5
        return stats["success"] / stats["total"]
    
    def _load_anger_stats(self) -> None:
        """æ€’ã‚Šçµ±è¨ˆèª­ã¿è¾¼ã¿"""
        try:
            if os.path.exists(self.anger_stats_file):
                with open(self.anger_stats_file, 'r', encoding='utf-8') as f:
                    self.anger_stats = json.load(f)
        except Exception as e:
            print(f"çµ±è¨ˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _save_anger_stats(self) -> None:
        """æ€’ã‚Šçµ±è¨ˆä¿å­˜"""
        try:
            with open(self.anger_stats_file, 'w', encoding='utf-8') as f:
                json.dump(self.anger_stats, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"çµ±è¨ˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    
    def get_simple_anger_report(self) -> str:
        """ã²ã‚ã‚†ããƒ¢ãƒ¼ãƒ‰åŠ¹æœãƒ¬ãƒãƒ¼ãƒˆ"""
        hiroyuki_rate = self._get_success_rate("hiroyuki")
        hiroyuki_total = self.anger_stats.get("hiroyuki", {}).get("total", 0)
        
        report = "ğŸ“Š ã²ã‚ã‚†ãé¢¨AIåŠ¹æœåˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n"
        report += "="*40 + "\n"
        report += f"ğŸ¤” ã²ã‚ã‚†ãã‚‰ã—ã•: {hiroyuki_rate:.1%} ({hiroyuki_total}å›ä½¿ç”¨)\n"
        
        if hiroyuki_total > 0:
            if hiroyuki_rate >= 0.7:
                report += "\nğŸ† çµæœ: ã²ã‚ã‚†ãã‚‰ã—ã•ãŒé«˜åº¦ã«å†ç¾ã•ã‚Œã¦ã„ã¾ã™ï¼"
            elif hiroyuki_rate >= 0.5:
                report += "\nğŸ“ˆ çµæœ: ã¾ã‚ã¾ã‚ã²ã‚ã‚†ãã£ã½ã„ã§ã™ã­"
            else:
                report += "\nğŸ¤” çµæœ: ã¾ã ã²ã‚ã‚†ãã‚‰ã—ã•ãŒè¶³ã‚Šãªã„ã§ã™ã­"
        else:
            report += "\nğŸ“ˆ ã¾ã ãƒ‡ãƒ¼ã‚¿ãŒä¸ååˆ†ã§ã™"
        
        return report


# GoogleColabç’°å¢ƒå°‚ç”¨éŸ³å£°æ©Ÿèƒ½
def setup_drive_and_find_model_dir(default_model_dir: str = "model_assets", model_name: str = "yoshino_test") -> Optional[str]:
    """Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¦ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢"""
    try:
        # ã‚ˆã‚Šè©³ç´°ãªColabç’°å¢ƒãƒã‚§ãƒƒã‚¯
        import os
        import sys
        
        # è¤‡æ•°ã®æ–¹æ³•ã§Colabç’°å¢ƒã‚’ç¢ºèª
        colab_indicators = [
            'google.colab' in sys.modules,
            os.path.exists('/content'),
            os.environ.get('COLAB_GPU'),
            'COLAB_TPU_ADDR' in os.environ,
            hasattr(__builtins__, '__IPYTHON__') and os.path.exists('/content')
        ]
        
        is_colab = any(colab_indicators)
        print(f"ğŸ” ç’°å¢ƒãƒã‚§ãƒƒã‚¯: Colab={is_colab}, indicators={colab_indicators}")
        
        if not is_colab:
            print("âš ï¸ Colabç’°å¢ƒã§ã¯ãªã„ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¾ã™")
            if os.path.exists(default_model_dir):
                return default_model_dir
            else:
                print(f"âŒ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {default_model_dir}")
                return None
        
        # Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆï¼ˆColabç’°å¢ƒã®ã¿ï¼‰
        try:
            from google.colab import drive
            print("âœ“ google.colabãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
            
            drive_mount_point = "/content/drive"
            
            # æ—¢ã«ãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if os.path.exists(f"{drive_mount_point}/MyDrive"):
                print("âœ“ Googleãƒ‰ãƒ©ã‚¤ãƒ–ã¯æ—¢ã«ãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã„ã¾ã™")
            else:
                print("ğŸ“ Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆä¸­...")
                
                # ã‚«ãƒ¼ãƒãƒ«çŠ¶æ…‹ã®ãƒã‚§ãƒƒã‚¯ã¨ãƒã‚¦ãƒ³ãƒˆå®Ÿè¡Œ
                try:
                    # IPythonã‚«ãƒ¼ãƒãƒ«ã®çŠ¶æ…‹ç¢ºèª
                    try:
                        from IPython import get_ipython
                        ipython = get_ipython()
                        if ipython is None:
                            print("âš ï¸ IPythonã‚«ãƒ¼ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»£æ›¿æ–¹æ³•ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                            # ä»£æ›¿ãƒã‚¦ãƒ³ãƒˆæ–¹æ³•ã‚’è©¦è¡Œ
                            import subprocess
                            result = subprocess.run(['ls', '/content/drive/MyDrive'], capture_output=True, text=True)
                            if result.returncode == 0:
                                print("âœ“ ãƒ‰ãƒ©ã‚¤ãƒ–ã¯æ—¢ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã™")
                            else:
                                print("âŒ ãƒ‰ãƒ©ã‚¤ãƒ–ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒã§ãã¾ã›ã‚“")
                                return None
                        else:
                            print("âœ“ IPythonã‚«ãƒ¼ãƒãƒ«ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                            # é€šå¸¸ã®ãƒã‚¦ãƒ³ãƒˆå®Ÿè¡Œ
                            drive.mount(drive_mount_point, force_remount=False)
                            print("âœ“ Googleãƒ‰ãƒ©ã‚¤ãƒ–ãŒãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¾ã—ãŸ")
                            
                    except Exception as kernel_error:
                        print(f"âš ï¸ ã‚«ãƒ¼ãƒãƒ«ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {kernel_error}")
                        
                        # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥çš„ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
                        print("ğŸ”„ ç›´æ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèªã‚’å®Ÿè¡Œä¸­...")
                        import subprocess
                        try:
                            # Google DriveãŒãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                            check_cmd = ['test', '-d', '/content/drive/MyDrive']
                            result = subprocess.run(check_cmd, capture_output=True)
                            
                            if result.returncode == 0:
                                print("âœ“ Google Drive ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™")
                            else:
                                print("âŒ Google Driveãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                                print("ğŸ’¡ æ‰‹å‹•ã§ãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¦ãã ã•ã„:")
                                print("   from google.colab import drive")
                                print("   drive.mount('/content/drive')")
                                return None
                                
                        except Exception as subprocess_error:
                            print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {subprocess_error}")
                            return None
                            
                except Exception as mount_error:
                    print(f"âŒ ãƒ‰ãƒ©ã‚¤ãƒ–ãƒã‚¦ãƒ³ãƒˆè©³ç´°ã‚¨ãƒ©ãƒ¼: {mount_error}")
                    print(f"ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(mount_error)}")
                    
                    # ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ã«å¿œã˜ãŸå¯¾å‡¦
                    error_str = str(mount_error)
                    if 'kernel' in error_str:
                        print("ğŸ’¡ ã‚«ãƒ¼ãƒãƒ«ã‚¨ãƒ©ãƒ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚æ‰‹å‹•ãƒã‚¦ãƒ³ãƒˆã‚’æ¨å¥¨ã—ã¾ã™:")
                        print("   1. æ–°ã—ã„ã‚»ãƒ«ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œ:")
                        print("   from google.colab import drive")
                        print("   drive.mount('/content/drive')")
                        print("   2. èªè¨¼ã‚’å®Œäº†ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„")
                    
                    return None
            
        except ImportError as import_error:
            print(f"âŒ google.colabã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {import_error}")
            return None
        
        # å¯èƒ½æ€§ã®ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹å€™è£œ
        possible_paths = [
            f"{drive_mount_point}/MyDrive/Style-Bert-VITS2/model_assets",  # å„ªå…ˆãƒ‘ã‚¹
            f"{drive_mount_point}/MyDrive/{default_model_dir}",
            f"{drive_mount_point}/MyDrive/model_assets",
            f"{drive_mount_point}/MyDrive/models",
            f"{drive_mount_point}/MyDrive/voice_models",
            f"{drive_mount_point}/MyDrive/AI_models/{default_model_dir}",
            f"/content/{default_model_dir}",  # ãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            default_model_dir  # å…ƒã®ãƒ‘ã‚¹
        ]
        
        print("ğŸ” ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢ä¸­...")
        for path in possible_paths:
            print(f"  ãƒã‚§ãƒƒã‚¯ä¸­: {path}")
            if os.path.exists(path):
                # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ã‚‚ç¢ºèª
                model_subdir = os.path.join(path, model_name)
                if os.path.exists(model_subdir):
                    print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {path}")
                    return path
                else:
                    print(f"  âš ï¸ {path}ã¯å­˜åœ¨ã—ã¾ã™ãŒã€{model_name}ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¡ˆå†…
        print("âŒ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        print("\nğŸ“‹ è§£æ±ºæ–¹æ³•:")
        print("1. Googleãƒ‰ãƒ©ã‚¤ãƒ–ã®ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–ã«ä»¥ä¸‹ã®æ§‹é€ ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®:")
        print("   MyDrive/Style-Bert-VITS2/model_assets/yoshino_test/")
        print("2. ã¾ãŸã¯ã€Colabã®å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        print("\nğŸ’¡ æ¨å¥¨ãƒ‰ãƒ©ã‚¤ãƒ–æ§‹é€ :")
        print("   MyDrive/")
        print("   â””â”€â”€ Style-Bert-VITS2/")
        print("       â””â”€â”€ model_assets/")
        print("           â””â”€â”€ yoshino_test/")
        print("               â”œâ”€â”€ config.json")
        print("               â”œâ”€â”€ model.pth")
        print("               â””â”€â”€ style_vectors.npy")
        
        return None
        
    except Exception as e:
        print(f"âŒ ãƒ‰ãƒ©ã‚¤ãƒ–ãƒã‚¦ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return None


def is_colab_environment() -> bool:
    """GoogleColabç’°å¢ƒã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆå¼·åŒ–ç‰ˆï¼‰"""
    try:
        import os
        import sys
        
        # è¤‡æ•°ã®æŒ‡æ¨™ã§Colabç’°å¢ƒã‚’åˆ¤å®š
        indicators = {
            'google_colab_module': False,
            'content_dir': os.path.exists('/content'),
            'colab_gpu_env': bool(os.environ.get('COLAB_GPU')),
            'colab_tpu_env': bool(os.environ.get('COLAB_TPU_ADDR')),
            'ipython_and_content': hasattr(__builtins__, '__IPYTHON__') and os.path.exists('/content')
        }
        
        # google.colabãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å­˜åœ¨ç¢ºèª
        try:
            import google.colab
            indicators['google_colab_module'] = True
        except ImportError:
            indicators['google_colab_module'] = False
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±å‡ºåŠ›
        print(f"ğŸ” Colabç’°å¢ƒåˆ¤å®šè©³ç´°: {indicators}")
        
        # ã„ãšã‚Œã‹ã®æŒ‡æ¨™ãŒçœŸã§ã‚ã‚Œã°Colabç’°å¢ƒã¨åˆ¤å®š
        is_colab = any(indicators.values())
        print(f"ğŸ¯ æœ€çµ‚åˆ¤å®š: Colabç’°å¢ƒ = {is_colab}")
        
        return is_colab
        
    except Exception as e:
        print(f"âš ï¸ Colabç’°å¢ƒåˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
        return False


def initialize_tts_system(model_name: str = "yoshino_test", model_dir: str = "model_assets", device: str = "auto") -> Optional[object]:
    """éŸ³å£°åˆæˆã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼å¯¾å¿œï¼‰"""
    # GoogleColabç’°å¢ƒãƒã‚§ãƒƒã‚¯
    if not is_colab_environment():
        print("âš ï¸ éŸ³å£°æ©Ÿèƒ½ã¯GoogleColabç’°å¢ƒã§ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™")
        print("ğŸ’¡ GoogleColabã§ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return None
    
    try:
        # Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¦ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã‚’æ¤œç´¢
        model_dir = setup_drive_and_find_model_dir(model_dir, model_name)
        if model_dir is None:
            return None
            
        # style_bert_vits2ã®å­˜åœ¨ç¢ºèªã¨è©³ç´°ãƒã‚§ãƒƒã‚¯
        import importlib.util
        spec = importlib.util.find_spec("style_bert_vits2")
        if spec is None:
            print("âš ï¸ style_bert_vits2ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            print("ğŸ’¡ Colabã§ !pip install style-bert-vits2 ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return None
        
        # TTSModelã‚¯ãƒ©ã‚¹ã®å­˜åœ¨ç¢ºèª
        try:
            from style_bert_vits2.tts_model import TTSModel
            print("âœ“ TTSModelã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«æˆåŠŸã—ã¾ã—ãŸ")
        except ImportError as e:
            print(f"âš ï¸ TTSModelã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
            print("ğŸ’¡ style_bert_vits2ãŒå¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            return None
        
        # æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        try:
            print("ğŸ”„ Style-Bert-VITS2ã®æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
            from style_bert_vits2 import bert_models
            from style_bert_vits2.constants import Languages
            
            # æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰
            bert_models.load_model(Languages.JP, "ku-nlp/deberta-v2-large-japanese-char-wwm")
            bert_models.load_tokenizer(Languages.JP, "ku-nlp/deberta-v2-large-japanese-char-wwm")
            print("âœ“ æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸ")
        except Exception as bert_error:
            print(f"âš ï¸ BERTãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {bert_error}")
            print("ğŸ’¡ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨BERTãƒ¢ãƒ‡ãƒ«ã‚’è©¦è¡Œã—ã¾ã™...")
            try:
                bert_models.load_model(Languages.JP, "cl-tohoku/bert-base-japanese-v3")
                bert_models.load_tokenizer(Languages.JP, "cl-tohoku/bert-base-japanese-v3")
                print("âœ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯BERTãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«æˆåŠŸã—ã¾ã—ãŸ")
            except Exception as fallback_error:
                print(f"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯BERTãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚‚å¤±æ•—: {fallback_error}")
                print("ğŸ’¡ éŸ³å£°åˆæˆã§BERTã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            
        # Style-Bert-VITS2ã®åˆæœŸåŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆapp.pyã¨åŒæ§˜ï¼‰
        print("ğŸŒ pyopenjtalk_workerã‚’åˆæœŸåŒ–ä¸­...")
        from style_bert_vits2.nlp.japanese import pyopenjtalk_worker
        from style_bert_vits2.nlp.japanese.user_dict import update_dict
        
        # pyopenjtalk_workerã®åˆæœŸåŒ–ï¼ˆStyle-Bert-VITS2ã®app.pyã¨åŒã˜ï¼‰
        try:
            pyopenjtalk_worker.initialize_worker()
            print("âœ“ pyopenjtalk_workeråˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âŒ pyopenjtalk_workeråˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
            import traceback
            print("âŒ è©³ç´°ãªã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:")
            traceback.print_exc()
            raise e
        
        # è¾æ›¸ãƒ‡ãƒ¼ã‚¿ã®é©ç”¨
        print("ğŸ“š è¾æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’é©ç”¨ä¸­...")
        update_dict()
        print("âœ“ è¾æ›¸ãƒ‡ãƒ¼ã‚¿é©ç”¨å®Œäº†")
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
        print("ğŸš€ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­...")
        tts_server = start_background_tts_server(model_dir, model_name, device)
        
        if tts_server:
            print("âœ“ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼èµ·å‹•å®Œäº†")
            return tts_server
        else:
            print("âš ï¸ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return None
        
    except ImportError as e:
        print(f"âš ï¸ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³ã—ã¦ã„ã¾ã™: {e}")
        print("ğŸ’¡ Colabã§ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")
        return None
    except Exception as e:
        print(f"âš ï¸ éŸ³å£°ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def initialize_bert_for_japanese() -> bool:
    """Style-Bert-VITS2ç”¨ã®æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"""
    try:
        print("ğŸ”„ Style-Bert-VITS2ã®æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
        from style_bert_vits2 import bert_models
        from style_bert_vits2.constants import Languages
        
        # ãƒ¡ã‚¤ãƒ³ã®BERTãƒ¢ãƒ‡ãƒ«ï¼ˆæ¨å¥¨ï¼‰
        try:
            bert_models.load_model(Languages.JP, "ku-nlp/deberta-v2-large-japanese-char-wwm")
            bert_models.load_tokenizer(Languages.JP, "ku-nlp/deberta-v2-large-japanese-char-wwm")
            print("âœ“ æ—¥æœ¬èªBERTãƒ¢ãƒ‡ãƒ«ï¼ˆdeberta-v2-largeï¼‰ã®åˆæœŸåŒ–ã«æˆåŠŸ")
            return True
        except Exception as main_error:
            print(f"âš ï¸ ãƒ¡ã‚¤ãƒ³BERTãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼: {main_error}")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«
            try:
                bert_models.load_model(Languages.JP, "cl-tohoku/bert-base-japanese-v3")
                bert_models.load_tokenizer(Languages.JP, "cl-tohoku/bert-base-japanese-v3")
                print("âœ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯BERTãƒ¢ãƒ‡ãƒ«ï¼ˆbert-base-japaneseï¼‰ã®åˆæœŸåŒ–ã«æˆåŠŸ")
                return True
            except Exception as fallback_error:
                print(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯BERTãƒ¢ãƒ‡ãƒ«ã‚‚å¤±æ•—: {fallback_error}")
                return False
                
    except ImportError as e:
        print(f"âŒ BERTãƒ¢ãƒ‡ãƒ«æ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
        return False
    except Exception as e:
        print(f"âŒ BERTåˆæœŸåŒ–ã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def start_background_tts_server(model_dir: str, model_name: str, device: str) -> Optional[object]:
    """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§TTSã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ï¼ˆmodel_load.pyæ–¹å¼ã€ãƒ¬ã‚¬ã‚·ãƒ¼é–¢æ•°ï¼‰"""
    print("âš ï¸ ã“ã®é–¢æ•°ã¯å»ƒæ­¢äºˆå®šã§ã™ã€‚model_load.pyã‚’ç›´æ¥ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
    try:
        import threading
        import time
        from pathlib import Path
        import torch
        import os
        import sys
        
        # BERTå•é¡Œã‚’äº‹å‰ã«è§£æ±º
        print("ğŸ”§ BERTè¨­å®šã®å•é¡Œã‚’è§£æ±ºä¸­...")
        try:
            # 1. transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å‹•çš„ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
            try:
                from transformers import AutoTokenizer, AutoModel
                print("âœ… transformersåˆ©ç”¨å¯èƒ½")
            except ImportError:
                print("ğŸ“¥ transformersãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
                import subprocess
                subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'transformers', 'torch'])
                from transformers import AutoTokenizer, AutoModel
                print("âœ… transformersã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†")
            
            # 2. BERTãƒ¢ãƒ‡ãƒ«ã®Google Colabå¯¾å¿œæº–å‚™
            # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ç”¨BERTãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š
            if "/content/drive/" in model_dir:
                # Google Driveã®å ´åˆã¯ãã®ãƒ¢ãƒ‡ãƒ«ç”¨ã®BERTãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
                bert_dir = Path(model_dir).parent / 'bert_models'
            else:
                # ãƒ­ãƒ¼ã‚«ãƒ«ã®å ´åˆã¯å¾“æ¥é€šã‚Š
                bert_dir = Path(model_dir).parent / 'bert_models' / 'japanese'
            
            bert_dir.mkdir(parents=True, exist_ok=True)
            print(f"ğŸ“ BERTãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {bert_dir}")
            
            # è¤‡æ•°ã®BERTãƒ¢ãƒ‡ãƒ«å€™è£œã‚’è©¦è¡Œ
            bert_model_candidates = [
                'ku-nlp/deberta-v2-large-japanese-char-wwm',
                'cl-tohoku/bert-large-japanese-char-v2', 
                'cl-tohoku/bert-base-japanese-v3'
            ]
            
            bert_success = False
            for bert_model in bert_model_candidates:
                if (bert_dir / 'config.json').exists():
                    bert_success = True
                    print(f"âœ… æ—¢å­˜BERTãƒ¢ãƒ‡ãƒ«ç™ºè¦‹: {bert_dir}")
                    break
                    
                print(f"ğŸ“¥ {bert_model} BERTãƒ¢ãƒ‡ãƒ«æº–å‚™ä¸­...")
                try:
                    tokenizer = AutoTokenizer.from_pretrained(
                        bert_model,
                        cache_dir=str(bert_dir)
                    )
                    model = AutoModel.from_pretrained(
                        bert_model,
                        cache_dir=str(bert_dir)
                    )
                    bert_success = True
                    print(f"âœ… {bert_model} BERTãƒ¢ãƒ‡ãƒ«æº–å‚™å®Œäº†")
                    break
                except Exception as download_error:
                    print(f"âš ï¸ {bert_model} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {download_error}")
                    continue
            
            if not bert_success:
                print("âš ï¸ å…¨ã¦ã®BERTãƒ¢ãƒ‡ãƒ«æº–å‚™ã«å¤±æ•—ã€éŸ³å£°åˆæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            
            # 3. Style-Bert-VITS2ã®BERTè¨­å®šã‚’å®Œå…¨ãƒ‘ãƒƒãƒ
            try:
                from style_bert_vits2.nlp import bert_models
                
                # DEFAULT_BERT_TOKENIZER_PATHSã‚’å¼·åˆ¶è¨­å®š
                if not hasattr(bert_models, 'DEFAULT_BERT_TOKENIZER_PATHS'):
                    bert_models.DEFAULT_BERT_TOKENIZER_PATHS = {}
                
                bert_models.DEFAULT_BERT_TOKENIZER_PATHS['JP'] = str(bert_dir)
                
                # Languagesã‚¯ãƒ©ã‚¹ã®å®Œå…¨ãƒ‘ãƒƒãƒ
                if not hasattr(bert_models, 'Languages'):
                    # Languagesã‚¯ãƒ©ã‚¹è‡ªä½“ã‚’ä½œæˆ
                    class Languages:
                        pass
                    bert_models.Languages = Languages()
                
                # JPè¨€èªã®å‹•çš„è¨­å®šï¼ˆè¤‡æ•°ã®æ–¹æ³•ã§ç¢ºå®Ÿã«è¨­å®šï¼‰
                class JP:
                    bert_tokenizer_path = str(bert_dir)
                    code = 'JP'
                    
                    @classmethod
                    def get_path(cls):
                        return str(bert_dir)
                    
                    def __str__(self):
                        return 'JP'
                
                # JPè¨­å®šã®è¤‡æ•°æ–¹æ³•ã§ã®è¿½åŠ 
                bert_models.Languages.JP = JP()
                setattr(bert_models.Languages, 'JP', JP())
                
                # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å†…ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ã‚‚è¨­å®š
                setattr(bert_models, 'JP_BERT_PATH', str(bert_dir))
                
                # ç’°å¢ƒå¤‰æ•°ã‚‚è¨­å®šï¼ˆæœ€å¼·ã®ä¿é™ºï¼‰
                os.environ['STYLE_BERT_VITS2_BERT_JP'] = str(bert_dir)
                os.environ['BERT_MODELS_JP'] = str(bert_dir)
                
                print(f"âœ… å®Œå…¨BERTè¨­å®šãƒ‘ãƒƒãƒå®Œäº†: {bert_dir}")
                print(f"âœ… DEFAULT_BERT_TOKENIZER_PATHS: {getattr(bert_models, 'DEFAULT_BERT_TOKENIZER_PATHS', {})}")
                print(f"âœ… Languages.JP: {getattr(bert_models.Languages, 'JP', None)}")
                
            except Exception as patch_error:
                print(f"âš ï¸ BERTãƒ‘ãƒƒãƒã‚¨ãƒ©ãƒ¼ã€ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒã‚’è©¦è¡Œ: {patch_error}")
                
                # ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒã«ã‚ˆã‚‹å¼·åˆ¶è¨­å®š
                try:
                    import sys
                    import types
                    
                    # bert_modelsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å–å¾—ã¾ãŸã¯ä½œæˆ
                    if 'style_bert_vits2.nlp.bert_models' in sys.modules:
                        bert_mod = sys.modules['style_bert_vits2.nlp.bert_models']
                    else:
                        bert_mod = types.ModuleType('bert_models')
                        sys.modules['style_bert_vits2.nlp.bert_models'] = bert_mod
                    
                    # å¼·åˆ¶çš„ã«è¨­å®š
                    bert_mod.DEFAULT_BERT_TOKENIZER_PATHS = {'JP': str(bert_dir)}
                    
                    # Languagesã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
                    languages_obj = types.SimpleNamespace()
                    jp_obj = types.SimpleNamespace()
                    jp_obj.bert_tokenizer_path = str(bert_dir)
                    jp_obj.code = 'JP'
                    languages_obj.JP = jp_obj
                    bert_mod.Languages = languages_obj
                    
                    print(f"âœ… ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒã«ã‚ˆã‚‹BERTè¨­å®šå®Œäº†: {bert_dir}")
                    
                except Exception as monkey_error:
                    print(f"âš ï¸ ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒã‚‚å¤±æ•—: {monkey_error}")
                    # ç’°å¢ƒå¤‰æ•°ã®ã¿ã§é ‘å¼µã‚‹
                    os.environ['BERT_BASE_DIR'] = str(bert_dir.parent)
                    os.environ['JP_BERT_PATH'] = str(bert_dir)
                    print(f"âœ… ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹BERTè¨­å®š: {bert_dir}")
        
        except Exception as bert_setup_error:
            print(f"âš ï¸ BERTè¨­å®šã‚¨ãƒ©ãƒ¼ã€TTSåˆæœŸåŒ–ã‚’ç¶šè¡Œ: {bert_setup_error}")
        
        # æ–°ã—ã„API: TTSModelã‚’ç›´æ¥ä½¿ç”¨
        from style_bert_vits2.tts_model import TTSModel
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®ç¢ºèªã¨è‡ªå‹•æ¤œç´¢ï¼ˆãƒ‘ã‚¹å‡¦ç†ä¿®æ­£ï¼‰
        model_dir_path = Path(model_dir)
        if model_name:
            model_path = model_dir_path / model_name
        else:
            model_path = model_dir_path
        
        # ãƒ‘ã‚¹ã®æ­£è¦åŒ–ã¨å­˜åœ¨ç¢ºèª
        if not model_path.exists():
            print(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_path}")
            print(f"ğŸ“ æ¤œç´¢å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {model_dir_path}")
            if model_dir_path.exists():
                print(f"ğŸ“‚ åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«: {list(model_dir_path.iterdir())}")
            return None
        
        # åŸºæœ¬çš„ãªå¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPathã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦å®‰å…¨ã«å‡¦ç†ï¼‰
        required_files = {}
        config_file = model_path / 'config.json'
        style_vectors_file = model_path / 'style_vectors.npy'
        
        if config_file.exists():
            required_files['config.json'] = config_file
        if style_vectors_file.exists():
            required_files['style_vectors.npy'] = style_vectors_file
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å€™è£œã‚’å®‰å…¨ã«æ¤œç´¢
        model_file_candidates = []
        try:
            # æ˜ç¤ºçš„ãªãƒ•ã‚¡ã‚¤ãƒ«åã§ã®æ¤œç´¢
            for ext in ['.safetensors', '.pth', '.pt', '.ckpt']:
                explicit_file = model_path / f'model{ext}'
                if explicit_file.exists():
                    model_file_candidates.append(explicit_file)
            
            # globæ¤œç´¢ï¼ˆä¾‹å¤–å‡¦ç†ä»˜ãï¼‰
            for pattern in ['*.safetensors', '*.pth', '*.pt', '*.ckpt']:
                try:
                    model_file_candidates.extend(list(model_path.glob(pattern)))
                except OSError as glob_error:
                    print(f"âš ï¸ Globãƒ‘ã‚¿ãƒ¼ãƒ³ {pattern} æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {glob_error}")
        except Exception as search_error:
            print(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {search_error}")
        
        # é‡è¤‡é™¤å»
        model_file_candidates = list(set(model_file_candidates))
        
        model_file = None
        for candidate in model_file_candidates:
            try:
                if candidate.exists() and candidate.is_file():
                    model_file = candidate
                    print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {candidate}")
                    break
            except Exception as candidate_error:
                print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªã‚¨ãƒ©ãƒ¼ {candidate}: {candidate_error}")
        
        if model_file is None:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:")
            print(f"   æ¤œç´¢å¯¾è±¡: {[str(c) for c in model_file_candidates[:6]]}")  # æœ€åˆã®6å€‹ã‚’è¡¨ç¤º
            print(f"   ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹: {list(model_path.glob('*')) if model_path.exists() else 'ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“'}")
            return None
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºå®š
        required_files['model'] = model_file
        
        # ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        missing_files = []
        for file_type, file_path in required_files.items():
            if file_type == 'model':
                continue  # æ—¢ã«ãƒã‚§ãƒƒã‚¯æ¸ˆã¿
            if not file_path.exists():
                missing_files.append(f"{file_type}: {file_path}")
        
        if missing_files:
            print(f"âš ï¸ ä¸€éƒ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:")
            for missing in missing_files:
                print(f"   - {missing}")
            
            # style_vectors.npyãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä½œæˆã‚’è©¦è¡Œ
            if 'style_vectors.npy' in [m.split(':')[0] for m in missing_files]:
                print(f"ğŸ’¡ style_vectors.npyãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™")
                # ç°¡æ˜“çš„ãªç©ºã®style vectorsãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                import numpy as np
                try:
                    np.save(model_path / 'style_vectors.npy', np.array([]))
                    required_files['style_vectors.npy'] = model_path / 'style_vectors.npy'
                    print(f"âœ“ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®style_vectors.npyã‚’ä½œæˆã—ã¾ã—ãŸ")
                except Exception as e:
                    print(f"âš ï¸ style_vectors.npyä½œæˆã«å¤±æ•—: {e}")
                    return None
        
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ç¢ºèªå®Œäº†: {model_name}")
        
        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
        if device == "auto":
            if torch.cuda.is_available():
                device = "cuda"
                print("âœ“ GPU(CUDA)ã‚’ä½¿ç”¨ã—ã¾ã™")
            else:
                device = "cpu" 
                print("âš ï¸ GPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUã‚’ä½¿ç”¨ã—ã¾ã™")
        
        print(f"ğŸ“ TTSModelã‚’ç›´æ¥åˆæœŸåŒ–ä¸­... (ãƒ‘ã‚¹: {model_path})")
        
        # BERTãƒ¢ãƒ‡ãƒ«ã®äº‹å‰åˆæœŸåŒ–
        if not initialize_bert_for_japanese():
            print("âš ï¸ BERTãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€TTSModelä½œæˆã‚’ç¶šè¡Œã—ã¾ã™")
        
        # TTSModelã‚’ç›´æ¥ä½œæˆï¼ˆæ–°ã—ã„APIï¼‰
        try:
            print(f"ğŸ”„ TTSModelåˆæœŸåŒ–ä¸­...")
            print(f"   - ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {required_files['model']}")
            print(f"   - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {required_files['config.json']}")
            print(f"   - ã‚¹ã‚¿ã‚¤ãƒ«ãƒ™ã‚¯ãƒˆãƒ«: {required_files['style_vectors.npy']}")
            print(f"   - ãƒ‡ãƒã‚¤ã‚¹: {device}")
            
            # Pathã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆStyle-Bert-VITS2ã¯æ–‡å­—åˆ—ãƒ‘ã‚¹ã‚’è¦æ±‚ï¼‰
            tts_model = TTSModel(
                model_path=str(required_files['model']),
                config_path=str(required_files['config.json']),
                style_vec_path=str(required_files['style_vectors.npy']),
                device=device
            )
            print("âœ… TTSModelä½œæˆæˆåŠŸ")
        except ImportError as e:
            print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            print("ğŸ’¡ style_bert_vits2ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
            return None
        except FileNotFoundError as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
            print("ğŸ’¡ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            return None
        except RuntimeError as e:
            if "CUDA" in str(e):
                print(f"âŒ CUDAé–¢é€£ã‚¨ãƒ©ãƒ¼: {e}")
                print("ğŸ’¡ CPUãƒ‡ãƒã‚¤ã‚¹ã§å†è©¦è¡Œã—ã¾ã™")
                try:
                    tts_model = TTSModel(
                        model_path=required_files['model'],
                        config_path=required_files['config.json'],
                        style_vec_path=required_files['style_vectors.npy'],
                        device="cpu"
                    )
                    print("âœ… CPUã§ã®TTSModelä½œæˆã«æˆåŠŸ")
                except Exception as cpu_error:
                    print(f"âŒ CPUå†è©¦è¡Œã‚‚å¤±æ•—: {cpu_error}")
                    return None
            else:
                print(f"âŒ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
                return None
        except Exception as e:
            print(f"âŒ TTSModelä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {model_dir}")
            print(f"âŒ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
            import traceback
            print("âŒ è©³ç´°ãªã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:")
            traceback.print_exc()
            print("\nğŸ’¡ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:")
            print("   1. style_bert_vits2ãŒæœ€æ–°ç‰ˆã‹ãƒã‚§ãƒƒã‚¯: pip install --upgrade style-bert-vits2")
            print("   2. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯")
            print("   3. ååˆ†ãªãƒ¡ãƒ¢ãƒªãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯")
            print("   4. Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®äº’æ›æ€§ã‚’ãƒã‚§ãƒƒã‚¯")
            return None
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼ã‚¯ãƒ©ã‚¹ï¼ˆTTSModelç›´æ¥ä½¿ç”¨ï¼‰
        class BackgroundTTSServer:
            def __init__(self, tts_model, model_name):
                self.tts_model = tts_model
                self.model_name = model_name
                self.is_running = True
                
            def synthesize_speech(self, text: str, output_path: str = "output.wav", **kwargs) -> Optional[str]:
                """éŸ³å£°åˆæˆã‚’å®Ÿè¡Œï¼ˆTTSModelç›´æ¥ä½¿ç”¨ï¼‰"""
                try:
                    print(f"ğŸµ éŸ³å£°åˆæˆå®Ÿè¡Œä¸­: '{text[:50]}{'...' if len(text) > 50 else ''}'")
                    
                    # TTSModelã®inferãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç›´æ¥å‘¼ã³å‡ºã—ï¼ˆæ–°ã—ã„APIï¼‰
                    try:
                        # Style-Bert-VITS2ã®æ¨™æº–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§inferå®Ÿè¡Œ
                        sr, audio = self.tts_model.infer(
                            text=text,
                            language="JP",  # æ—¥æœ¬èª
                            speaker_id=kwargs.get('speaker_id', 0),
                            reference_audio_path=kwargs.get('reference_audio_path', None),
                            sdp_ratio=kwargs.get('sdp_ratio', 0.2),
                            noise=kwargs.get('noise', 0.6), 
                            noise_w=kwargs.get('noise_w', 0.8),
                            length=kwargs.get('length', 1.0)
                        )
                        
                        print(f"âœ… éŸ³å£°åˆæˆæˆåŠŸ - ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {sr}")
                        
                    except Exception as infer_error:
                        print(f"âš ï¸ inferãƒ¡ã‚½ãƒƒãƒ‰ã§ã‚¨ãƒ©ãƒ¼: {infer_error}")
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä»–ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è©¦è¡Œ
                        available_methods = [method for method in dir(self.tts_model) 
                                           if not method.startswith('_') and callable(getattr(self.tts_model, method))]
                        print(f"ğŸ” åˆ©ç”¨å¯èƒ½ãªãƒ¡ã‚½ãƒƒãƒ‰: {available_methods}")
                        raise infer_error
                    
                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
                    if audio is not None:
                        from scipy.io import wavfile
                        import numpy as np
                        
                        # numpyã®å‹å¤‰æ›ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                        if isinstance(audio, np.ndarray):
                            if audio.dtype == np.float32 or audio.dtype == np.float64:
                                # float -> int16 å¤‰æ›
                                audio_int16 = (audio * 32767).astype(np.int16)
                            else:
                                audio_int16 = audio
                        else:
                            audio_int16 = np.array(audio, dtype=np.int16)
                        
                        # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                        wavfile.write(output_path, sr, audio_int16)
                        print(f"âœ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†: {output_path}")
                        return output_path
                    else:
                        print("âš ï¸ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒNoneã§ã™")
                        return None
                        
                except Exception as e:
                    print(f"âš ï¸ éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
                    print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
                    print(f"âš ï¸ å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
                    import traceback
                    print("âš ï¸ è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:")
                    traceback.print_exc()
                    return None
                    
            def stop(self):
                """ã‚µãƒ¼ãƒãƒ¼åœæ­¢"""
                self.is_running = False
                print("ğŸ›‘ TTSã‚µãƒ¼ãƒãƒ¼ã‚’åœæ­¢ã—ã¾ã—ãŸ")
        
        # ã‚µãƒ¼ãƒãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        tts_server = BackgroundTTSServer(tts_model, model_name)
        
        print("âœ“ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¾ã—ãŸ")
        return tts_server
        
    except Exception as e:
        print(f"âš ï¸ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def initialize_native_tts_system(model_dir: str, model_name: str, device: str) -> Optional[object]:
    """Style-Bert-VITS2ã®ãƒã‚¤ãƒ†ã‚£ãƒ–æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ãŸTTSåˆæœŸåŒ–ï¼ˆTTSModelç›´æ¥ä½¿ç”¨ï¼‰"""
    try:
        from pathlib import Path
        import torch
        from style_bert_vits2.tts_model import TTSModel
        
        # Colabç’°å¢ƒã§ã®ãƒ‡ãƒã‚¤ã‚¹è¨­å®šï¼ˆGPUå„ªå…ˆï¼‰
        if device == "auto":
            if torch.cuda.is_available():
                device = "cuda"
                print("âœ“ GPU(CUDA)ã‚’ä½¿ç”¨ã—ã¾ã™")
            else:
                device = "cpu"
                print("âš ï¸ GPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚CPUã‚’ä½¿ç”¨ã—ã¾ã™")
        
        print(f"ğŸ“ TTSModelã‚’ç›´æ¥åˆæœŸåŒ–ä¸­... (ãƒ‘ã‚¹: {model_dir}/{model_name})")
        
        # BERTãƒ¢ãƒ‡ãƒ«ã®äº‹å‰åˆæœŸåŒ–
        if not initialize_bert_for_japanese():
            print("âš ï¸ BERTãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€TTSModelä½œæˆã‚’ç¶šè¡Œã—ã¾ã™")
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®ç¢ºèªã¨è‡ªå‹•æ¤œç´¢
        model_path = Path(model_dir) / model_name
        
        # åŸºæœ¬çš„ãªå¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«
        required_files = {
            'config.json': model_path / 'config.json',
            'style_vectors.npy': model_path / 'style_vectors.npy'
        }
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å€™è£œã‚’æ¤œç´¢ï¼ˆè¤‡æ•°å½¢å¼å¯¾å¿œï¼‰
        model_file_candidates = [
            model_path / 'model.safetensors',
            model_path / 'model.pth', 
            model_path / 'model.pt',
            model_path / 'model.ckpt',
            *model_path.glob('*.safetensors'),
            *model_path.glob('*.pth'),
            *model_path.glob('*.pt')
        ]
        
        model_file = None
        for candidate in model_file_candidates:
            if candidate.exists() and candidate.is_file():
                model_file = candidate
                print(f"âœ“ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {candidate}")
                break
        
        if model_file is None:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:")
            print(f"   æ¤œç´¢å¯¾è±¡: {[str(c) for c in model_file_candidates[:6]]}")
            print(f"   ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹: {list(model_path.glob('*')) if model_path.exists() else 'ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“'}")
            return None
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºå®š
        required_files['model'] = model_file
        
        # ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        missing_files = []
        for file_type, file_path in required_files.items():
            if file_type == 'model':
                continue  # æ—¢ã«ãƒã‚§ãƒƒã‚¯æ¸ˆã¿
            if not file_path.exists():
                missing_files.append(f"{file_type}: {file_path}")
        
        if missing_files:
            print(f"âš ï¸ ä¸€éƒ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:")
            for missing in missing_files:
                print(f"   - {missing}")
            
            # style_vectors.npyãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä½œæˆã‚’è©¦è¡Œ
            if 'style_vectors.npy' in [m.split(':')[0] for m in missing_files]:
                print(f"ğŸ’¡ style_vectors.npyãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™")
                # ç°¡æ˜“çš„ãªç©ºã®style vectorsãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                import numpy as np
                try:
                    np.save(model_path / 'style_vectors.npy', np.array([]))
                    required_files['style_vectors.npy'] = model_path / 'style_vectors.npy'
                    print(f"âœ“ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®style_vectors.npyã‚’ä½œæˆã—ã¾ã—ãŸ")
                except Exception as e:
                    print(f"âš ï¸ style_vectors.npyä½œæˆã«å¤±æ•—: {e}")
                    return None
        
        # TTSModelã‚’ç›´æ¥ä½œæˆ
        try:
            print(f"ğŸ”„ TTSModelåˆæœŸåŒ–ä¸­...")
            print(f"   - ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {required_files['model']}")
            print(f"   - è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {required_files['config.json']}")
            print(f"   - ã‚¹ã‚¿ã‚¤ãƒ«ãƒ™ã‚¯ãƒˆãƒ«: {required_files['style_vectors.npy']}")
            print(f"   - ãƒ‡ãƒã‚¤ã‚¹: {device}")
            
            tts_model = TTSModel(
                model_path=required_files['model'],
                config_path=required_files['config.json'],
                style_vec_path=required_files['style_vectors.npy'],
                device=device
            )
            print(f"âœ“ TTSModelåˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"âŒ TTSModelåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
            import traceback
            print("âŒ è©³ç´°ãªã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹:")
            traceback.print_exc()
            return None
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹ã‚’ä½œæˆï¼ˆTTSModelç›´æ¥ä½¿ç”¨ï¼‰
        class NativeTTSModel:
            def __init__(self, tts_model, model_name):
                self.tts_model = tts_model
                self.model_name = model_name
            
            def inference(self, text: str, output_path: str, **kwargs) -> str:
                """éŸ³å£°åˆæˆã‚’å®Ÿè¡Œï¼ˆTTSModelç›´æ¥ä½¿ç”¨ï¼‰"""
                try:
                    print(f"ğŸµ éŸ³å£°åˆæˆå®Ÿè¡Œä¸­: '{text[:50]}{'...' if len(text) > 50 else ''}'")
                    
                    # TTSModelã®inferãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç›´æ¥å‘¼ã³å‡ºã—
                    sr, audio = self.tts_model.infer(
                        text=text,
                        language="JP",
                        speaker_id=kwargs.get('speaker_id', 0),
                        reference_audio_path=kwargs.get('reference_audio_path', None),
                        sdp_ratio=kwargs.get('sdp_ratio', 0.2),
                        noise=kwargs.get('noise', 0.6),
                        noise_w=kwargs.get('noise_w', 0.8),
                        length=kwargs.get('length', 1.0)
                    )
                    
                    print(f"âœ… éŸ³å£°åˆæˆæˆåŠŸ - ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {sr}")
                    
                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
                    if audio is not None:
                        from scipy.io import wavfile
                        import numpy as np
                        
                        # numpyã®å‹å¤‰æ›
                        if isinstance(audio, np.ndarray):
                            if audio.dtype == np.float32 or audio.dtype == np.float64:
                                audio_int16 = (audio * 32767).astype(np.int16)
                            else:
                                audio_int16 = audio
                        else:
                            audio_int16 = np.array(audio, dtype=np.int16)
                        
                        wavfile.write(output_path, sr, audio_int16)
                        print(f"âœ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†: {output_path}")
                        return output_path
                    else:
                        print("âš ï¸ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒNoneã§ã™")
                        return None
                        
                except Exception as e:
                    print(f"âš ï¸ éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
                    print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
                    print(f"âš ï¸ å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
                    import traceback
                    print("âš ï¸ è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:")
                    traceback.print_exc()
                    return None
        
        return NativeTTSModel(tts_model, model_name)
        
    except Exception as e:
        print(f"âš ï¸ ãƒã‚¤ãƒ†ã‚£ãƒ–TTSã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def text_to_speech_if_available(text: str, output_path: str = "output.wav") -> Optional[str]:
    """éŸ³å£°åˆæˆã®å®Ÿè¡Œï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼å¯¾å¿œï¼‰"""
    if not is_colab_environment():
        print("âš ï¸ éŸ³å£°åˆæˆã¯GoogleColabç’°å¢ƒã§ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™")
        return None
        
    try:
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«éŸ³å£°ã‚µãƒ¼ãƒãƒ¼ã®ç¢ºèª
        if not hasattr(text_to_speech_if_available, '_tts_server'):
            print("âš ï¸ TTSã‚µãƒ¼ãƒãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return None
            
        tts_server = getattr(text_to_speech_if_available, '_tts_server')
        if tts_server is None:
            print("âš ï¸ TTSã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return None
            
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã—ã¦éŸ³å£°åˆæˆ
        if hasattr(tts_server, 'synthesize_speech'):
            result_path = tts_server.synthesize_speech(text, output_path)
            return result_path
        else:
            # å¾“æ¥ã®æ–¹å¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
            result_path = tts_server.inference(text, output_path)
            return str(result_path)
        
    except Exception as e:
        print(f"âš ï¸ éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None


def mount_drive_safely() -> bool:
    """å®‰å…¨ã«Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆã™ã‚‹é–¢æ•°"""
    try:
        import os
        from google.colab import drive
        
        drive_mount_point = "/content/drive"
        
        # æ—¢ã«ãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if os.path.exists(f"{drive_mount_point}/MyDrive"):
            print("âœ… Googleãƒ‰ãƒ©ã‚¤ãƒ–ã¯æ—¢ã«ãƒã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã„ã¾ã™")
            return True
        
        print("ğŸ“ Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’æ‰‹å‹•ãƒã‚¦ãƒ³ãƒˆä¸­...")
        
        # å®‰å…¨ãªãƒã‚¦ãƒ³ãƒˆå®Ÿè¡Œ
        try:
            drive.mount(drive_mount_point)
            print("âœ… Googleãƒ‰ãƒ©ã‚¤ãƒ–ã®ãƒã‚¦ãƒ³ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸ")
            return True
        except Exception as e:
            print(f"âŒ ãƒã‚¦ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ ãƒ‰ãƒ©ã‚¤ãƒ–ãƒã‚¦ãƒ³ãƒˆé–¢æ•°ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def integrated_langchain_mode() -> None:
    """çµ±åˆLangChainãƒ¢ãƒ¼ãƒ‰ã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆéŸ³å£°æ©Ÿèƒ½ä»˜ãï¼‰"""
    print("\n=== çµ±åˆLangChainé«˜æ©Ÿèƒ½è‡ªç„¶è¨€èªãƒ¢ãƒ¼ãƒ‰ï¼ˆéŸ³å£°ä»˜ãï¼‰ ===")
    print("LangChainã‚’ä½¿ã£ã¦ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã¨ã‚¿ã‚¹ã‚¯ã®æƒ…å ±ã‚’æ¤œç´¢ã—ã¦ãŠç­”ãˆã—ã¾ã™ã€‚")
    if is_colab_environment():
        print("ğŸµ AIã®å¿œç­”ã‚’éŸ³å£°ã§ã‚‚å†ç”Ÿã—ã¾ã™ï¼ï¼ˆGoogleColabç’°å¢ƒï¼‰")
    else:
        print("ğŸ’¬ éŸ³å£°æ©Ÿèƒ½ã¯GoogleColabç’°å¢ƒã§ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™")
    print("")
    print("'æˆ»ã‚‹'ã¨å…¥åŠ›ã™ã‚‹ã¨é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã«æˆ»ã‚Šã¾ã™ã€‚\n")
    
    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼ã®åˆæœŸåŒ–ï¼ˆGoogleColabç’°å¢ƒã®ã¿ï¼‰
    tts_server = None
    if is_colab_environment():
        try:
            print("ğŸµ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼ã‚’åˆæœŸåŒ–ä¸­...")
            tts_server = initialize_tts_system()
            if tts_server:
                # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«ä¿å­˜ï¼ˆå¾Œã§ä½¿ç”¨ã™ã‚‹ãŸã‚ï¼‰
                text_to_speech_if_available._tts_server = tts_server
                print("âœ“ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–å®Œäº†\n")
            else:
                print("âš ï¸ TTSã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆé€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§ç¶šè¡Œï¼‰\n")
        except Exception as e:
            print(f"âš ï¸ TTSã‚µãƒ¼ãƒãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            print("ğŸ’¡ éŸ³å£°ãªã—ã§ç¶šè¡Œã—ã¾ã™\n")
    else:
        print("ğŸ’¡ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã¯éŸ³å£°æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™\n")
    
    try:
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
        print("ğŸ¤– çµ±åˆLangChainã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...")
        agent = IntegratedLangChainAgent()
        
        if agent.llm_available:
            print("âœ“ LLMæ©Ÿèƒ½ä»˜ãã§åˆæœŸåŒ–å®Œäº†\n")
        else:
            print("âš ï¸ LLMãªã—ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–å®Œäº†ï¼ˆåŸºæœ¬æ©Ÿèƒ½ã¯åˆ©ç”¨å¯èƒ½ï¼‰\n")
            print("ğŸ’¡ é«˜åº¦ãªLLMæ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ãŸã„å ´åˆã¯ã€OPENROUTER_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚\n")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    
    # å¯¾è©±ãƒ«ãƒ¼ãƒ—ï¼ˆColabå¯¾å¿œï¼‰
    while True:
        try:
            # Colabç’°å¢ƒã§ã®å…¥åŠ›å¯¾å¿œ
            if is_colab_environment():
                user_input = input("ğŸ’¬ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ'æˆ»ã‚‹'ã§çµ‚äº†ï¼‰: ")
            else:
                user_input = input("ğŸ’¬ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ çµ±åˆLangChainé«˜æ©Ÿèƒ½è‡ªç„¶è¨€èªãƒ¢ãƒ¼ãƒ‰ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            break
        except Exception as e:
            print(f"âš ï¸ å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {e}")
            print("ğŸ’¡ Colabã§ã¯ç›´æ¥å…¥åŠ›ãŒã§ããªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚")
            print("ä»¥ä¸‹ã®ã‚ˆã†ã«ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã§ç›´æ¥å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š")
            print("""
# è³ªå•ä¾‹ã‚’ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã§ç›´æ¥å®Ÿè¡Œ
from integrated_langchain import IntegratedLangChainAgent
agent = IntegratedLangChainAgent()
response = agent.process_query("ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ã¯ï¼Ÿ")
print(response)
""")
            break
        
        user_input = user_input.strip()
        
        # çµ‚äº†æ¡ä»¶
        if user_input.lower() in ['æˆ»ã‚‹', 'back', 'exit', 'quit', '']:
            print("ğŸ‘‹ çµ±åˆLangChainé«˜æ©Ÿèƒ½è‡ªç„¶è¨€èªãƒ¢ãƒ¼ãƒ‰ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            break
        
        if not user_input:
            print("â“ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            continue
        
        # ç‰¹åˆ¥ã‚³ãƒãƒ³ãƒ‰
        if user_input.lower() in ['æ€’ã‚Šåˆ†æ', 'åŠ¹æœãƒ¬ãƒãƒ¼ãƒˆ', 'ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æ', 'motivation report']:
            report = agent.get_simple_anger_report()
            print(f"\n{report}\n")
            print("-" * 60)
            continue
        
        print("\nğŸ” çµ±åˆLangChainãŒæƒ…å ±ã‚’æ¤œç´¢ãƒ»åˆ†æã—ã¦ã„ã¾ã™...")
        
        # agentã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®process_queryãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã‚’å‘¼ã³å‡ºã—ã¦ã„ã‚‹
        response = agent.process_query(user_input)
        
        print(f"\nğŸ¤– **å›ç­”**:\n{response}\n")
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã—ãŸéŸ³å£°ç”Ÿæˆ
        if tts_server:
            try:
                # AIã®å‡ºåŠ›ã‚’ai_voiceå¤‰æ•°ã«æ ¼ç´
                ai_voice = response
                
                print("ğŸµ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼ã§éŸ³å£°ã‚’ç”Ÿæˆä¸­...")
                # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰TTSã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã—ãŸéŸ³å£°ç”Ÿæˆ
                audio_file = text_to_speech_if_available(ai_voice, "out.wav")
                
                if audio_file:
                    print("ğŸ”Š éŸ³å£°ã‚’å†ç”Ÿã—ã¾ã™...")
                    try:
                        from IPython.display import Audio, display
                        display(Audio(audio_file))
                        print(f"âœ“ éŸ³å£°å†ç”Ÿå®Œäº†: {audio_file}")
                    except ImportError:
                        print("âš ï¸ Jupyterç’°å¢ƒã§ã¯ãªã„ãŸã‚éŸ³å£°å†ç”Ÿã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                        print(f"ğŸ’¡ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ: {audio_file}")
                else:
                    print("âš ï¸ éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                    
            except Exception as e:
                print(f"âš ï¸ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        
        print("-" * 60)


def colab_quick_chat(question: str = "ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ã¯ï¼Ÿ") -> str:
    """GoogleColabç”¨ã®ç°¡å˜ãƒãƒ£ãƒƒãƒˆé–¢æ•°ï¼ˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä»˜ãï¼‰"""
    try:
        print("ğŸ¤– AIè‡ªç„¶è¨€èªãƒ¢ãƒ¼ãƒ‰ã‚’èµ·å‹•ã—ã¦ã„ã¾ã™...")
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
        agent = IntegratedLangChainAgent()
        
        if not agent.llm_available:
            return "âŒ LLMãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        
        print(f"ğŸ’¬ è³ªå•: {question}")
        print("ğŸ” AI ãŒå›ç­”ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
        
        # è³ªå•å‡¦ç†
        response = agent.process_query(question)
        
        print(f"\nğŸ¤– **å›ç­”**:\n{response}\n")
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®ææ¡ˆ
        if agent.tts_available:
            print("ğŸµ ã“ã®å›ç­”ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã‹ï¼Ÿ (y/n)")
            print("ğŸ’¡ 'y' ã‚’å…¥åŠ›ã™ã‚‹ã¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™")
            
            # Google Colabç’°å¢ƒã§ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            try:
                import time
                save_filename = f"todo_response_{int(time.time())}.mp3"
                agent.download_voice_file(response, save_filename)
            except Exception as audio_error:
                print(f"âš ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {audio_error}")
        
        return response
        
    except Exception as e:
        error_msg = f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        print(error_msg)
        return error_msg

def colab_setup_style_bert():
    """Google Colabç”¨ Style-Bert-VITS2ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    try:
        print("ğŸ”§ Style-Bert-VITS2ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # Google Driveãƒã‚¦ãƒ³ãƒˆç¢ºèª
        drive_path = "/content/drive/MyDrive"
        if not os.path.exists(drive_path):
            print("ğŸ“ Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¦ã„ã¾ã™...")
            try:
                from google.colab import drive
                drive.mount('/content/drive')
                print("âœ… Google Driveãƒã‚¦ãƒ³ãƒˆå®Œäº†")
            except ImportError:
                print("âŒ Google Colabç’°å¢ƒã§ãªã„ã€ã¾ãŸã¯ãƒã‚¦ãƒ³ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
        else:
            print("âœ… Google Driveæ—¢ã«ãƒã‚¦ãƒ³ãƒˆæ¸ˆã¿")
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ç¢ºèª
        model_paths = [
            "/content/drive/MyDrive/Style-Bert-VITS2/model_assets/yoshino_test",
            "/content/drive/MyDrive/Style-Bert-VITS2/model_assets/hiroyuki"
        ]
        
        found_models = []
        for path in model_paths:
            if os.path.exists(path):
                files = os.listdir(path)
                has_config = 'config.json' in files
                has_model = any(f.endswith('.safetensors') or f.endswith('.pth') for f in files)
                if has_config and has_model:
                    found_models.append(path)
                    print(f"âœ… æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«ç™ºè¦‹: {path}")
                else:
                    print(f"âš ï¸ ä¸å®Œå…¨ãªãƒ¢ãƒ‡ãƒ«: {path} (config:{has_config}, model:{has_model})")
            else:
                print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹å­˜åœ¨ã—ã¾ã›ã‚“: {path}")
        
        if found_models:
            print(f"ğŸ‰ {len(found_models)} å€‹ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            return True
        else:
            print("âŒ åˆ©ç”¨å¯èƒ½ãªã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("ğŸ’¡ Google Driveã®Style-Bert-VITS2ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ¢ãƒ‡ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„")
            return False
            
    except Exception as e:
        print(f"âŒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_yoshino_model_simple(text: str = "ã“ã‚“ã«ã¡ã¯ã€ãƒ†ã‚¹ãƒˆã§ã™"):
    """Google Colabç’°å¢ƒå°‚ç”¨ï¼šã‚·ãƒ³ãƒ—ãƒ«ãªyoshino_testãƒ†ã‚¹ãƒˆ"""
    try:
        print("ğŸ§ª ã€Google Colabå°‚ç”¨ã€‘ã‚·ãƒ³ãƒ—ãƒ«ãªyoshino_testãƒ†ã‚¹ãƒˆé–‹å§‹...")
        
        # å¿…è¦æœ€å°é™ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        import os
        import tempfile
        
        # Google Colabç’°å¢ƒç¢ºèª
        try:
            import google.colab
            print("âœ… Google Colabç’°å¢ƒã‚’ç¢ºèª")
        except ImportError:
            print("âŒ Google Colabç’°å¢ƒã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®é–¢æ•°ã¯Google Colabå°‚ç”¨ã§ã™ã€‚")
            return False
        
        # model_load.py ã‚’ç›´æ¥ä½¿ç”¨
        print("ğŸ“¦ model_load.py ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­...")
        from model_load import load_model
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ã‚¹è¨­å®š
        model_dir = "/content/drive/MyDrive/Style-Bert-VITS2/model_assets"
        model_name = "yoshino_test"
        
        if not os.path.exists(model_dir):
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_dir}")
            print("ğŸ’¡ Google DriveãŒãƒã‚¦ãƒ³ãƒˆã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
            return False
        
        print(f"ğŸ¯ ãƒ¢ãƒ‡ãƒ«: {model_name}")
        print(f"ğŸ“ ãƒ‘ã‚¹: {model_dir}")
        print(f"ğŸ“ ãƒ†ã‚¹ãƒˆæ–‡ç« : {text}")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        print("\nğŸ“‹ å®Ÿè¡Œã‚³ãƒ¼ãƒ‰:")
        print(f"sample_model = load_model('{model_name}', model_dir='{model_dir}', device='cuda')")
        
        sample_model = load_model(model_name, model_dir=model_dir, device="cuda")
        
        print("âœ… sample_model èª­ã¿è¾¼ã¿æˆåŠŸ")
        
        # ä¸€å›ã ã‘ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        out_path = "/content/yoshino_simple_test.wav"
        print(f"\nğŸµ éŸ³å£°ç”Ÿæˆãƒ†ã‚¹ãƒˆ:")
        print(f"sample_model.inference('{text}', '{out_path}')")
        
        result = sample_model.inference(text, out_path)
        
        print(f"âœ… éŸ³å£°ç”Ÿæˆå®Œäº†: {result}")
        if os.path.exists(out_path):
            size = os.path.getsize(out_path)
            print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {size} bytes")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚·ãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_yoshino_model(text: str = "ã“ã‚“ã«ã¡ã¯ã€ãƒ†ã‚¹ãƒˆã§ã™"):
    """yoshino_testãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œãƒ†ã‚¹ãƒˆï¼ˆmodel_load.pyå¿…é ˆä½¿ç”¨ç‰ˆï¼‰"""
    try:
        print("ğŸ§ª yoshino_testãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆï¼ˆmodel_load.pyä½¿ç”¨ï¼‰ã‚’é–‹å§‹...")
        
        # ä¾å­˜é–¢ä¿‚ã®ç¢ºèª
        print("ğŸ” model_load.pyä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯...")
        agent = IntegratedLangChainAgent()
        agent._ensure_model_load_dependencies()
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®Ÿè£…ä¾‹è¡¨ç¤º
        print("\n" + "="*60)
        print("ğŸ¯ ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®Ÿè£…ä¾‹:")
        print("="*60)
        print("from model_load import load_model")
        print("")
        print("# ç¬¬1å¼•æ•°ã«ãƒ¢ãƒ‡ãƒ«åã€model_dirã¨deviceã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°")
        print("sample_model = load_model(\"ãƒ¢ãƒ‡ãƒ«å\", model_dir=\"/content/model_assets\", device=\"cuda\")")
        print("")
        print("# sample_modelã‚’ä½¿ã„å›ã—ã¦inferenceå®Ÿè¡Œ")
        print("sample_model.inference(\"aaa\", \"/content/out.wav\")")
        print("sample_model.inference(\"æ¬¡ã®ç™ºè©±\", \"/content/out2.wav\")")
        print("="*60)
        print("")
        
        # model_load.pyã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆ
        from model_load import load_model
        import torch
        import tempfile
        
        model_dir = "/content/drive/MyDrive/Style-Bert-VITS2/model_assets"
        model_name = "yoshino_test"
        
        if not os.path.exists(model_dir):
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_dir}")
            return False
        
        print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆå¯¾è±¡: {model_dir}/{model_name}")
        print(f"ğŸ“ ãƒ†ã‚¹ãƒˆæ–‡ç« : {text}")
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ”§ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã¨åŒã˜å½¢å¼ã§ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        print("ğŸ”§ ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        print(f"   å®Ÿè¡Œ: sample_model = load_model('{model_name}', model_dir='{model_dir}', device='{device}')")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å®Œå…¨ã«åŒã˜å‘¼ã³å‡ºã—æ–¹æ³•
        sample_model = load_model(
            model_name,  # ç¬¬1å¼•æ•°ã¨ã—ã¦ä½ç½®å¼•æ•°ã§æŒ‡å®šï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³æº–æ‹ ï¼‰
            model_dir=model_dir,  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³æº–æ‹ ï¼‰
            device=device,  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³æº–æ‹ ï¼‰
            preload_onnx_bert=False
        )
        
        print("âœ… sample_model åˆæœŸåŒ–æˆåŠŸï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰")
        print(f"  - ãƒ¢ãƒ‡ãƒ«å: {sample_model.info.model_name}")
        try:
            print(f"  - è©±è€…: {list(sample_model.spk2id.keys())}")
            print(f"  - ã‚¹ã‚¿ã‚¤ãƒ«: {list(sample_model.style2id.keys())}")
        except:
            print("  - è©±è€…ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«æƒ…å ±å–å¾—å¤±æ•—")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã®éŸ³å£°ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        print("\nğŸµ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã®é€£ç¶šéŸ³å£°ç”Ÿæˆãƒ†ã‚¹ãƒˆ:")
        print("   sample_model.inference(\"aaa\", \"/content/out.wav\")")
        print("   sample_model.inference(\"æ¬¡ã®ç™ºè©±\", \"/content/out2.wav\")")
        print("")
        
        # ãƒ†ã‚¹ãƒˆ1: "aaa"
        temp_dir = tempfile.gettempdir()
        out1_path = os.path.join(temp_dir, "out.wav")
        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆ1å®Ÿè¡Œ: sample_model.inference(\"aaa\", \"{out1_path}\")")
        result1 = sample_model.inference("aaa", out1_path)
        print(f"   âœ… å®Œäº†: {result1}")
        
        # ãƒ†ã‚¹ãƒˆ2: "æ¬¡ã®ç™ºè©±"  
        out2_path = os.path.join(temp_dir, "out2.wav")
        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆ2å®Ÿè¡Œ: sample_model.inference(\"æ¬¡ã®ç™ºè©±\", \"{out2_path}\")")
        result2 = sample_model.inference("æ¬¡ã®ç™ºè©±", out2_path)
        print(f"   âœ… å®Œäº†: {result2}")
        
        # ãƒ†ã‚¹ãƒˆ3: ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ†ã‚­ã‚¹ãƒˆ
        out3_path = os.path.join(temp_dir, "user_test.wav")
        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆ3å®Ÿè¡Œ: sample_model.inference(\"{text}\", \"{out3_path}\")")
        result3 = sample_model.inference(text, out3_path)
        print(f"   âœ… å®Œäº†: {result3}")
        
        # ç”Ÿæˆçµæœã‚µãƒãƒªãƒ¼
        print("\n" + "="*60)
        print("ğŸ“Š sample_model ä½¿ã„å›ã—ãƒ†ã‚¹ãƒˆçµæœ:")
        print("="*60)
        print(f"âœ… ãƒ†ã‚¹ãƒˆ1: aaa -> {out1_path}")
        print(f"âœ… ãƒ†ã‚¹ãƒˆ2: æ¬¡ã®ç™ºè©± -> {out2_path}")
        print(f"âœ… ãƒ†ã‚¹ãƒˆ3: {text} -> {out3_path}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
        for i, (path, description) in enumerate([(out1_path, "aaa"), (out2_path, "æ¬¡ã®ç™ºè©±"), (out3_path, text)], 1):
            if os.path.exists(path):
                size = os.path.getsize(path)
                print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«{i}: {size} bytes ({description})")
        
        # Google Colabç’°å¢ƒã®å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«ã™ã‚‹
        try:
            from google.colab import files
            import shutil
            import time
            
            print(f"\nğŸ§ Google Colabç’°å¢ƒ: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æº–å‚™ä¸­...")
            for i, (src_path, filename) in enumerate([(out1_path, "out.wav"), (out2_path, "out2.wav"), (out3_path, "user_test.wav")], 1):
                if os.path.exists(src_path):
                    colab_path = f"/content/{filename}"
                    shutil.copy(src_path, colab_path)
                    print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«{i}ä¿å­˜: {colab_path}")
                    
        except ImportError:
            print(f"ğŸ“ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†")
        
        print("\nâœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ sample_model ä½¿ã„å›ã—ãƒ†ã‚¹ãƒˆå®Œäº†!")
        return True
        
    except Exception as e:
        print(f"âŒ yoshino_testãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_yoshino_model_legacy(text: str = "ã“ã‚“ã«ã¡ã¯ã€ãƒ†ã‚¹ãƒˆã§ã™"):
    """yoshino_testãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œãƒ†ã‚¹ãƒˆï¼ˆmodel_load.pyä½¿ç”¨ç‰ˆï¼‰"""
    try:
        print("ğŸ§ª yoshino_testãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆï¼ˆmodel_load.pyç‰ˆï¼‰ã‚’é–‹å§‹...")
        
        # model_load.pyã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆ
        from model_load import load_model
        import torch
        import tempfile
        
        model_dir = "/content/drive/MyDrive/Style-Bert-VITS2/model_assets"
        model_name = "yoshino_test"
        
        if not os.path.exists(model_dir):
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_dir}")
            return False
        
        print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆå¯¾è±¡: {model_dir}/{model_name}")
        print(f"ğŸ“ ãƒ†ã‚¹ãƒˆæ–‡ç« : {text}")
        
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ”§ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
        
        # model_load.pyã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        loaded_model = load_model(
            model_name=model_name,
            model_dir=model_dir,
            device=device,
            preload_onnx_bert=False
        )
        
        print("âœ… yoshino_testãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–æˆåŠŸ")
        print(f"  - è©±è€…: {list(loaded_model.spk2id.keys())}")
        print(f"  - ã‚¹ã‚¿ã‚¤ãƒ«: {list(loaded_model.style2id.keys())}")
        
        # éŸ³å£°ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        print("ğŸµ éŸ³å£°ç”Ÿæˆãƒ†ã‚¹ãƒˆä¸­...")
        
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
            output_path = loaded_model.inference(
                text=text,
                output_path=temp_file.name,
                speaker_id=0,
                language="JP"
            )
            
            print(f"âœ… yoshino_testéŸ³å£°ç”ŸæˆæˆåŠŸ: {output_path}")
            
            # Google Colabç’°å¢ƒã®å ´åˆã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«ã™ã‚‹
            try:
                from google.colab import files
                import shutil
                import time
                
                save_filename = f"yoshino_test_legacy_{int(time.time())}.wav"
                shutil.copy(str(output_path), f"/content/{save_filename}")
                print(f"ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: /content/{save_filename}")
                
                print("ğŸ§ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã‹ï¼Ÿ")
                files.download(f"/content/{save_filename}")
                
            except ImportError:
                print(f"ğŸ“ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ: {output_path}")
        
        return True
        
    except Exception as e:
        print(f"âŒ yoshino_testãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def force_style_bert_mode():
    """Style-Bert-VITS2ã®ã¿ã‚’ä½¿ç”¨ï¼ˆgTTSã‚’ç„¡åŠ¹åŒ–ï¼‰"""
    try:
        print("ğŸ¯ Style-Bert-VITS2å°‚ç”¨ãƒ¢ãƒ¼ãƒ‰ã§åˆæœŸåŒ–...")
        
        # gTTSã‚’ç„¡åŠ¹åŒ–ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
        agent = IntegratedLangChainAgent()
        
        # gTTSãŒè¨­å®šã•ã‚Œã¦ã„ãŸã‚‰å¼·åˆ¶çš„ã«Style-Bert-VITS2ã«åˆ‡ã‚Šæ›¿ãˆ
        if hasattr(agent, 'tts_model') and isinstance(agent.tts_model, str):
            print("âš ï¸ gTTSãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚Style-Bert-VITS2ã«å¼·åˆ¶åˆ‡ã‚Šæ›¿ãˆã—ã¾ã™...")
            agent.tts_available = False
            agent._initialize_style_bert_only()
        
        # sample_model ãƒ‘ã‚¿ãƒ¼ãƒ³ã®èª¬æ˜ã‚’è¿½åŠ 
        if hasattr(agent, 'tts_model') and agent.tts_model is not None:
            print("\n" + "="*60)
            print("ğŸ¯ ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆsample_modelï¼‰ã®ä½¿ç”¨æ–¹æ³•:")
            print("="*60)
            print("from model_load import load_model")
            print("")
            print("# sample_modelã¨ã—ã¦åˆæœŸåŒ–")
            print("sample_model = load_model(\"yoshino_test\", model_dir=\"/content/model_assets\", device=\"cuda\")")
            print("")
            print("# sample_modelã‚’ä½¿ã„å›ã—ã¦éŸ³å£°ç”Ÿæˆ")
            print("sample_model.inference(\"ãƒ†ã‚¹ãƒˆéŸ³å£°\", \"/content/out.wav\")")
            print("sample_model.inference(\"æ¬¡ã®éŸ³å£°\", \"/content/out2.wav\")")
            print("="*60)
            print("")
        
        return agent
        
    except Exception as e:
        print(f"âŒ Style-Bert-VITS2å°‚ç”¨ãƒ¢ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return None

def colab_voice_chat(question: str = "ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ã¯ï¼Ÿ") -> str:
    """Google Colabå°‚ç”¨ï¼šéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•ç”Ÿæˆãƒãƒ£ãƒƒãƒˆ"""
    try:
        print("ğŸµ éŸ³å£°ä»˜ããƒãƒ£ãƒƒãƒˆé–‹å§‹...")
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆæœŸåŒ–
        agent = IntegratedLangChainAgent()
        
        if not agent.llm_available:
            return "âŒ LLMãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        
        print(f"ğŸ’¬ è³ªå•: {question}")
        response = agent.process_query(question)
        print(f"\nğŸ¤– **å›ç­”**:\n{response}\n")
        
        # è‡ªå‹•éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
        if agent.tts_available:
            print("ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ç”Ÿæˆä¸­...")
            try:
                import time
                filename = f"hiroyuki_voice_auto_{int(time.time())}.mp3"
                agent.download_voice_file(response, filename)
            except Exception as e:
                print(f"âš ï¸ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        
        return response
        
    except Exception as e:
        error_msg = f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"
        print(error_msg)
        return error_msg

def colab_setup_guide():
    """GoogleColabç”¨ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰"""
    print("""
ğŸš€ GoogleColabç”¨ TODO AIã‚¢ãƒ—ãƒª ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ å¿…è¦ãªæº–å‚™:
1. OpenRouter APIã‚­ãƒ¼ã®è¨­å®š
2. Googleãƒ‰ãƒ©ã‚¤ãƒ–ã®ãƒã‚¦ãƒ³ãƒˆï¼ˆéŸ³å£°æ©Ÿèƒ½ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

## ğŸ’» ä½¿ç”¨æ–¹æ³•:

### æ–¹æ³•1: ç°¡å˜ãƒãƒ£ãƒƒãƒˆï¼ˆæ¨å¥¨ï¼‰
```python
# é€šå¸¸ãƒãƒ£ãƒƒãƒˆï¼ˆéŸ³å£°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
colab_quick_chat("ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ã‚’ç¢ºèªã—ã¦")
colab_quick_chat("æ˜æ—¥ã¾ã§ã«ãƒ¬ãƒãƒ¼ãƒˆã‚’æ›¸ãã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ") 

# éŸ³å£°è‡ªå‹•ç”Ÿæˆãƒãƒ£ãƒƒãƒˆï¼ˆGoogle Colabå°‚ç”¨ï¼‰
colab_voice_chat("ã²ã‚ã‚†ãé¢¨ã§ã‚¿ã‚¹ã‚¯çŠ¶æ³ã‚’æ•™ãˆã¦")
colab_voice_chat("ã‚¿ã‚¹ã‚¯ç®¡ç†ã«ã¤ã„ã¦ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¦")

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆåˆå›å®Ÿè¡Œæ¨å¥¨ï¼‰
colab_setup_style_bert()  # Google Driveãƒã‚¦ãƒ³ãƒˆ & ãƒ¢ãƒ‡ãƒ«ç¢ºèª

# ğŸ¯ 1. ã‚·ãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆï¼ˆæ¨å¥¨ - ã‚¨ãƒ©ãƒ¼ãŒå°‘ãªã„ï¼‰
test_yoshino_model_simple("ã“ã‚“ã«ã¡ã¯ã€ãƒ†ã‚¹ãƒˆã§ã™")

# ğŸ¯ 2. TODOã‚¢ãƒ—ãƒªã§ã®çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆä¿®æ­£ç‰ˆï¼‰
agent = IntegratedLangChainAgent()
agent.test_voice_synthesis("ã“ã‚“ã«ã¡ã¯ã€TODOã‚¢ãƒ—ãƒªã®éŸ³å£°åˆæˆã§ã™")

# ğŸ¯ 3. è©³ç´°ãƒ†ã‚¹ãƒˆï¼ˆè©³ã—ã„æƒ…å ±ãŒå¿…è¦ãªå ´åˆï¼‰
test_yoshino_model("ã“ã‚“ã«ã¡ã¯ã€yoshinoéŸ³å£°ãƒ†ã‚¹ãƒˆã§ã™")

# è¨ºæ–­æ©Ÿèƒ½ï¼ˆãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼‰
agent = IntegratedLangChainAgent()
agent.diagnose_tts_system()  # è©³ç´°è¨ºæ–­

# ğŸ¯ ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆsample_modelï¼‰
from model_load import load_model

# sample_modelã¨ã—ã¦åˆæœŸåŒ–ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šå½¢å¼ï¼‰
sample_model = load_model("ãƒ¢ãƒ‡ãƒ«å", model_dir="/content/model_assets", device="cuda")

# sample_modelã‚’ä½¿ã„å›ã—ã¦è¤‡æ•°éŸ³å£°ç”Ÿæˆ
sample_model.inference("aaa", "/content/out.wav")
sample_model.inference("æ¬¡ã®ç™ºè©±", "/content/out2.wav")

# å®Ÿéš›ã®ä¾‹ï¼ˆyoshino_testãƒ¢ãƒ‡ãƒ«ï¼‰
sample_model = load_model("yoshino_test", model_dir="/content/drive/MyDrive/Style-Bert-VITS2/model_assets", device="cuda")
sample_model.inference("ã“ã‚“ã«ã¡ã¯ã€ãƒ†ã‚¹ãƒˆã§ã™", "/content/yoshino_test1.wav")
sample_model.inference("ã•ã‚‰ã«æ¬¡ã®ãƒ†ã‚¹ãƒˆ", "/content/yoshino_test2.wav")

# ğŸ¯ 4. ã‚¢ãƒ—ãƒªçµ±åˆä½¿ç”¨ï¼ˆmodel_load.py + yoshino_testãƒ¢ãƒ‡ãƒ«è‡ªå‹•ä½¿ç”¨ï¼‰
agent = IntegratedLangChainAgent()  # Google Colabç’°å¢ƒã§ã¯è‡ªå‹•çš„ã«ã‚·ãƒ³ãƒ—ãƒ«ãƒ¢ãƒ¼ãƒ‰
response = agent.process_query("ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ã‚’æ•™ãˆã¦")  # yoshino_testãƒ¢ãƒ‡ãƒ«ã§éŸ³å£°ç”Ÿæˆ

# ğŸ¯ 5. å®Ÿéš›ã®TODOã‚¢ãƒ—ãƒªæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
agent = IntegratedLangChainAgent()
agent.process_query("æ˜æ—¥ã¾ã§ã«ãƒ¬ãƒãƒ¼ãƒˆã‚’æ›¸ãã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ")  # ã‚¿ã‚¹ã‚¯è¿½åŠ  + éŸ³å£°å¿œç­”
agent.process_query("ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ã‚’ç¢ºèª")  # ã‚¿ã‚¹ã‚¯ç¢ºèª + éŸ³å£°å¿œç­”
```

### æ–¹æ³•2: å¯¾è©±ãƒ¢ãƒ¼ãƒ‰
```python
# å¯¾è©±å¼ãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¥åŠ›ã«åˆ¶é™ã‚ã‚Šï¼‰
integrated_langchain_mode()
```

### æ–¹æ³•3: ç›´æ¥ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ“ä½œ
```python
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç›´æ¥æ“ä½œ
from integrated_langchain import IntegratedLangChainAgent
agent = IntegratedLangChainAgent()
response = agent.process_query("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®äºˆå®šã‚’ç¢ºèªã—ã¦")
print(response)
```

## ğŸµ éŸ³å£°æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ:
1. Googleãƒ‰ãƒ©ã‚¤ãƒ–ã‚’ãƒã‚¦ãƒ³ãƒˆã—ã¦System-Bert-VITS2ã®ãƒ¢ãƒ‡ãƒ«ã‚’é…ç½®
2. ãƒ‘ã‚¹: /content/drive/MyDrive/Style-Bert-VITS2/model_assets/yoshino_test/

## ğŸ“ ã‚ˆãã‚ã‚‹è³ªå•ä¾‹:
- "ä»Šæ—¥ã®ã‚¿ã‚¹ã‚¯ã¯ï¼Ÿ"
- "æ˜æ—¥ã¾ã§ã«ãƒ¬ãƒãƒ¼ãƒˆã‚’æ›¸ãã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã—ã¦"
- "å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã‚’æ•™ãˆã¦"
- "æ¥é€±ã®äºˆå®šã¯ï¼Ÿ"
- "ã‚¿ã‚¹ã‚¯ã®é€²æ—çŠ¶æ³ã‚’ç¢ºèª"
""")

if __name__ == "__main__":
    if is_colab_environment():
        print("ğŸ”§ GoogleColabç’°å¢ƒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
        colab_setup_guide()
        print("\nğŸ’¡ ã¾ãšã¯ colab_quick_chat('è³ªå•å†…å®¹') ã‚’è©¦ã—ã¦ãã ã•ã„ï¼")
    else:
        print("ğŸš€ çµ±åˆTODOã‚¢ãƒ—ãƒªã‚’èµ·å‹•ä¸­...")
        
        # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–
        agent = IntegratedLangChainAgent()
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        agent.get_system_info()
        
        # éŸ³å£°ãƒ†ã‚¹ãƒˆï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if agent.tts_available:
            print("\nğŸµ éŸ³å£°åˆæˆãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n):")
            if input().lower().startswith('y'):
                agent.test_tts_system()
        
        print("\nâœ… åˆæœŸåŒ–å®Œäº†ï¼é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã§èµ·å‹•ã—ã¾ã™ã€‚")
        integrated_langchain_mode()